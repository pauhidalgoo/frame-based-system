{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner import *\n",
    "from recurrent_models import *\n",
    "from transformer_prof import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 5/5\n",
      "\n",
      "Average Training Accuracy: 0.8384524464607239\n",
      "Average Training F1: 0.5182102680206299\n",
      "Average Training Loss: 1.418479037284851\n",
      "Average Validation Accuracy: 0.8514951467514038\n",
      "Average Validation F1: 0.6384996592998504\n",
      "Average Validation Loss: 1.1917312383651733\n",
      "Best Model Validation Accuracy: 0.8607209324836731\n",
      "Best Model Validation F1: 0.3615230619907379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_sizes = [512]\n",
    "vocab_size = [500]\n",
    "\n",
    "class_weights = [True]\n",
    "\n",
    "for emb_size in embedding_sizes:\n",
    "    for voc_size in vocab_size:\n",
    "        for clss_w in class_weights:\n",
    "            train_config = { 'use_sample_weights':clss_w}\n",
    "            hyperparams = {'vocab_size': voc_size, 'embedding_dim': emb_size, 'epochs': 3, 'batch_size': 32}\n",
    "            for name in model_types:\n",
    "                model = create_model(name)\n",
    "                basic = NamedEntityRecognition(model, hyperparams, training_times=5, train_config=train_config, verbosing=0, name=name)\n",
    "                basic.train_model()\n",
    "                basic.print_training_information()\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in training data: 119\n",
      "Training model 1/2Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\layer.py:1265: UserWarning: Layer 'transformer_block' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Dimensions must be equal, but are 100 and 50 for '{{node add_1}} = AddV2[T=DT_FLOAT](layer_normalization_2_1/add_2, sequential_3_1/dense_3_1/Add)' with input shapes: [?,45,100], [?,45,50].''\n",
      "  warnings.warn(\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\layer.py:360: UserWarning: `build()` was called on layer 'transformer_block', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Exception encountered when calling TransformerBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_block' (of type TransformerBlock). Either the `TransformerBlock.call()` method is incorrect, or you need to implement the `TransformerBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 100 and 50 for '{{node add_1}} = AddV2[T=DT_FLOAT](layer_normalization_2_1/add_2, sequential_3_1/dense_3_1/Add)' with input shapes: [?,45,100], [?,45,50].\u001b[0m\n\nArguments received by TransformerBlock.call():\n  • args=('<KerasTensor shape=(None, 45, 100), dtype=float32, sparse=False, name=keras_tensor_2>',)\n  • kwargs={'training': 'False'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m hyperparams \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m500\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32\u001b[39m}\n\u001b[0;32m      4\u001b[0m basic \u001b[38;5;241m=\u001b[39m NamedEntityRecognition(model, hyperparams, is_transformer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, train_config\u001b[38;5;241m=\u001b[39mtrain_config, verbosing\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mbasic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m basic\u001b[38;5;241m.\u001b[39mprint_training_information()\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Universitat\\5_Quatri\\TVD\\frame-based\\frame-based-system\\NAME ENTITY RECOGNITION\\ner.py:328\u001b[0m, in \u001b[0;36mNamedEntityRecognition.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    326\u001b[0m     callbacks_list\u001b[38;5;241m.\u001b[39mappend(EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m    327\u001b[0m \u001b[38;5;66;03m# Fit the model and capture the training history\u001b[39;00m\n\u001b[1;32m--> 328\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_pad_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_labels_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_pad_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_labels_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbosing\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m histories\u001b[38;5;241m.\u001b[39mappend(history\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\Documents\\Universitat\\5_Quatri\\TVD\\frame-based\\frame-based-system\\NAME ENTITY RECOGNITION\\transformer_prof.py:26\u001b[0m, in \u001b[0;36mTransformerBlock.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     24\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(out1)\n\u001b[0;32m     25\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout2(ffn_output, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayernorm2(\u001b[43mout1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mffn_output\u001b[49m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Exception encountered when calling TransformerBlock.call().\n\n\u001b[1mCould not automatically infer the output shape / dtype of 'transformer_block' (of type TransformerBlock). Either the `TransformerBlock.call()` method is incorrect, or you need to implement the `TransformerBlock.compute_output_spec() / compute_output_shape()` method. Error encountered:\n\nDimensions must be equal, but are 100 and 50 for '{{node add_1}} = AddV2[T=DT_FLOAT](layer_normalization_2_1/add_2, sequential_3_1/dense_3_1/Add)' with input shapes: [?,45,100], [?,45,50].\u001b[0m\n\nArguments received by TransformerBlock.call():\n  • args=('<KerasTensor shape=(None, 45, 100), dtype=float32, sparse=False, name=keras_tensor_2>',)\n  • kwargs={'training': 'False'}"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = create_transformer(embed_dim=embedding_dim)\n",
    "train_config = { 'use_sample_weights':True}\n",
    "hyperparams = {'vocab_size': 500, 'embedding_dim': embedding_dim, 'epochs': 3, 'batch_size': 32}\n",
    "basic = NamedEntityRecognition(model, hyperparams, is_transformer=True, training_times=2, train_config=train_config, verbosing=2, name=\"Transformer\")\n",
    "basic.train_model()\n",
    "basic.print_training_information()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
