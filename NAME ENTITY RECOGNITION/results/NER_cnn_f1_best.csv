architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
Conv1D_32,"{'name': 'sequential_2', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_1', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d', 'trainable': True, 'dtype': 'float32', 'filters': 32, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_1', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 32)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 32)}}], 'build_input_shape': (None, 46)}",0.9770454168319702,0.25988879799842834,0.9710146188735962,0.22494199872016907,2329.0,773.0,619.0,550.5,5916.5,0.4845096110120794,"['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.25      1.00      0.40         2\n           2       0.95      0.90      0.92        20\n           3       0.98      0.99      0.99       101\n           4       0.42      1.00      0.59         8\n           5       0.67      0.80      0.73         5\n           6       1.00      0.00      0.00         1\n           7       0.12      0.90      0.22        10\n           8       0.43      1.00      0.60         3\n           9       0.50      1.00      0.67         3\n          11       0.18      0.67      0.29         3\n          12       0.00      1.00      0.00         0\n          13       0.14      0.29      0.19         7\n          14       0.50      0.60      0.55         5\n          15       0.45      0.82      0.58        11\n          16       0.52      1.00      0.69        11\n          17       0.47      0.46      0.46        46\n          18       1.00      0.97      0.98        33\n          19       0.83      0.83      0.83         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          22       0.00      1.00      0.00         0\n          24       0.85      0.92      0.88        12\n          25       0.86      0.29      0.44       102\n          26       0.86      0.77      0.81        39\n          27       0.89      0.87      0.88        39\n          28       0.77      0.83      0.80        12\n          29       0.50      1.00      0.67         1\n          30       0.00      0.00      0.00         1\n          31       0.78      0.78      0.78         9\n          32       0.80      0.59      0.68        68\n          33       0.33      1.00      0.50         1\n          34       0.88      0.62      0.72        34\n          35       1.00      0.71      0.83        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.92      1.00      0.96        12\n          39       0.86      0.86      0.86         7\n          40       0.89      0.98      0.93        49\n          41       0.50      0.42      0.45        12\n          42       0.82      0.85      0.84        27\n          43       0.53      0.89      0.67         9\n          44       0.60      1.00      0.75         3\n          45       0.42      0.79      0.55        19\n          46       0.95      0.93      0.94       656\n          47       1.00      0.40      0.57         5\n          48       1.00      0.71      0.83         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.20      0.20      0.20         5\n          53       0.00      1.00      0.00         0\n          54       0.80      0.67      0.73         6\n          55       0.00      1.00      0.00         0\n          56       0.83      0.83      0.83         6\n          61       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.25      1.00      0.40         3\n          64       1.00      0.00      0.00         1\n          65       0.00      1.00      0.00         0\n          66       0.25      1.00      0.40        14\n          68       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       0.50      1.00      0.67         2\n          72       0.05      1.00      0.09         4\n          73       0.96      0.78      0.86       567\n          74       0.00      1.00      0.00         0\n          75       1.00      0.54      0.70        13\n          76       0.60      1.00      0.75         6\n          77       1.00      1.00      1.00        11\n          78       0.80      0.98      0.88        53\n          79       0.23      0.50      0.32         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          82       0.00      1.00      0.00         0\n          83       1.00      0.00      0.00         2\n          84       0.29      0.67      0.40         6\n          85       0.00      1.00      0.00         0\n          86       0.06      0.57      0.11         7\n          87       1.00      1.00      1.00        27\n          88       0.88      1.00      0.93         7\n          89       1.00      1.00      1.00         2\n          90       0.90      0.75      0.82        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          95       0.52      0.46      0.49        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.26      0.83      0.40         6\n         103       0.69      0.45      0.55        20\n         104       0.96      0.85      0.90       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.97      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         114       0.00      1.00      0.00         0\n         115       0.29      1.00      0.45         5\n         116       0.89      0.39      0.54       132\n         117       0.67      1.00      0.80         2\n         118       0.62      1.00      0.76         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.91     10056\n   macro avg       0.54      0.78      0.51     10056\nweighted avg       0.96      0.91      0.93     10056\n', '              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       1.00      1.00      1.00        20\n           3       0.99      0.99      0.99       101\n           4       0.50      1.00      0.67         8\n           5       0.67      0.40      0.50         5\n           6       1.00      0.00      0.00         1\n           7       0.12      0.50      0.20        10\n           8       0.43      1.00      0.60         3\n           9       0.38      1.00      0.55         3\n          10       0.00      1.00      0.00         0\n          11       0.50      0.33      0.40         3\n          12       0.00      1.00      0.00         0\n          13       0.17      0.57      0.26         7\n          14       0.33      0.60      0.43         5\n          15       0.50      0.73      0.59        11\n          16       0.50      0.82      0.62        11\n          17       0.59      0.43      0.50        46\n          18       0.94      1.00      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.80      1.00      0.89        12\n          25       0.84      0.42      0.56       102\n          26       0.94      0.82      0.88        39\n          27       0.92      0.85      0.88        39\n          28       0.80      0.67      0.73        12\n          29       0.33      1.00      0.50         1\n          30       0.00      0.00      0.00         1\n          31       0.67      0.44      0.53         9\n          32       0.88      0.53      0.66        68\n          33       0.00      0.00      0.00         1\n          34       0.88      0.65      0.75        34\n          35       0.83      0.77      0.80        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.92      1.00      0.96        12\n          39       0.86      0.86      0.86         7\n          40       0.92      0.98      0.95        49\n          41       0.42      0.42      0.42        12\n          42       0.68      0.93      0.78        27\n          43       0.20      1.00      0.33         9\n          44       0.50      1.00      0.67         3\n          45       0.35      0.84      0.49        19\n          46       0.96      0.92      0.94       656\n          47       1.00      1.00      1.00         5\n          48       0.78      1.00      0.88         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.25      0.20      0.22         5\n          53       0.00      1.00      0.00         0\n          54       0.71      0.83      0.77         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          57       0.00      1.00      0.00         0\n          60       0.00      1.00      0.00         0\n          61       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.33      1.00      0.50         3\n          64       0.00      0.00      0.00         1\n          65       0.00      1.00      0.00         0\n          66       0.30      1.00      0.46        14\n          68       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       0.29      1.00      0.44         2\n          72       0.44      1.00      0.62         4\n          73       0.96      0.94      0.95       567\n          75       1.00      0.54      0.70        13\n          76       0.80      0.67      0.73         6\n          77       0.92      1.00      0.96        11\n          78       0.74      0.98      0.85        53\n          79       0.40      0.33      0.36         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          83       0.00      0.00      0.00         2\n          84       0.20      0.17      0.18         6\n          86       0.11      0.29      0.16         7\n          87       0.90      1.00      0.95        27\n          88       0.78      1.00      0.88         7\n          89       1.00      1.00      1.00         2\n          90       1.00      0.75      0.86        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.56      0.58      0.57        24\n          96       0.00      1.00      0.00         0\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.15      0.83      0.25         6\n         103       0.53      0.45      0.49        20\n         104       0.95      0.85      0.89       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         107       0.00      1.00      0.00         0\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.95      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.31      1.00      0.48         5\n         116       0.90      0.72      0.80       132\n         117       0.67      1.00      0.80         2\n         118       0.73      1.00      0.84         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.51      0.77      0.51     10056\nweighted avg       0.96      0.93      0.94     10056\n']",1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
Conv1D_64,"{'name': 'sequential_5', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_3'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_3', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_1', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_3', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 64)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 64)}}], 'build_input_shape': (None, 46)}",0.9797267913818359,0.26476728916168213,0.9739470481872559,0.22870440781116486,2383.0,682.0,565.0,493.0,5300.5,0.5031120140969951,"['              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      1702\n           1       1.00      1.00      1.00         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.73      1.00      0.84         8\n           5       0.29      0.80      0.42         5\n           6       1.00      0.00      0.00         1\n           7       0.28      0.50      0.36        10\n           8       0.30      1.00      0.46         3\n           9       0.33      1.00      0.50         3\n          10       0.00      1.00      0.00         0\n          11       0.67      0.67      0.67         3\n          12       0.00      1.00      0.00         0\n          13       0.14      0.43      0.21         7\n          14       0.40      0.40      0.40         5\n          15       0.58      0.64      0.61        11\n          16       0.53      0.82      0.64        11\n          17       0.48      0.50      0.49        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.69      0.92      0.79        12\n          25       0.98      0.64      0.77       102\n          26       0.94      0.74      0.83        39\n          27       0.92      0.85      0.88        39\n          28       0.91      0.83      0.87        12\n          29       0.50      1.00      0.67         1\n          30       0.00      0.00      0.00         1\n          31       0.62      0.56      0.59         9\n          32       0.87      0.40      0.55        68\n          33       0.00      0.00      0.00         1\n          34       0.84      0.79      0.82        34\n          35       0.78      0.81      0.79        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       1.00      1.00      1.00        12\n          39       0.86      0.86      0.86         7\n          40       0.87      0.98      0.92        49\n          41       0.62      0.42      0.50        12\n          42       0.82      0.85      0.84        27\n          43       0.53      1.00      0.69         9\n          44       1.00      1.00      1.00         3\n          45       0.30      0.53      0.38        19\n          46       0.96      0.93      0.94       656\n          47       1.00      1.00      1.00         5\n          48       1.00      0.57      0.73         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.17      0.20      0.18         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          60       0.00      1.00      0.00         0\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       1.00      0.00      0.00         3\n          64       1.00      0.00      0.00         1\n          66       0.30      1.00      0.46        14\n          67       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.05      1.00      0.09         4\n          73       0.95      0.79      0.87       567\n          75       1.00      0.54      0.70        13\n          76       0.55      1.00      0.71         6\n          77       1.00      1.00      1.00        11\n          78       0.81      0.98      0.89        53\n          79       0.23      0.50      0.32         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          83       1.00      0.00      0.00         2\n          84       0.17      0.17      0.17         6\n          85       0.00      1.00      0.00         0\n          86       0.06      0.57      0.11         7\n          87       1.00      1.00      1.00        27\n          88       0.88      1.00      0.93         7\n          89       1.00      1.00      1.00         2\n          90       0.90      0.75      0.82        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.56      0.62      0.59        24\n          96       0.00      1.00      0.00         0\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.24      1.00      0.39         6\n         103       0.64      0.45      0.53        20\n         104       0.95      0.86      0.90       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.97      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.33      1.00      0.50         5\n         116       0.93      0.42      0.58       132\n         117       0.67      1.00      0.80         2\n         118       0.67      1.00      0.80         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.56      0.77      0.53     10056\nweighted avg       0.96      0.93      0.94     10056\n', '              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.40      1.00      0.57         2\n           2       1.00      1.00      1.00        20\n           3       0.99      0.99      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.50      1.00      0.67         5\n           6       1.00      0.00      0.00         1\n           7       0.23      0.70      0.34        10\n           8       0.30      1.00      0.46         3\n           9       0.38      1.00      0.55         3\n          11       0.50      0.33      0.40         3\n          12       0.00      1.00      0.00         0\n          13       0.09      0.43      0.14         7\n          14       1.00      0.20      0.33         5\n          15       0.50      0.82      0.62        11\n          16       0.40      0.73      0.52        11\n          17       0.32      0.48      0.38        46\n          18       1.00      0.97      0.98        33\n          19       0.75      1.00      0.86         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.94      0.74      0.82       102\n          26       0.87      0.67      0.75        39\n          27       0.87      0.85      0.86        39\n          28       0.85      0.92      0.88        12\n          29       0.33      1.00      0.50         1\n          30       0.00      0.00      0.00         1\n          31       0.60      0.67      0.63         9\n          32       0.70      0.56      0.62        68\n          33       0.20      1.00      0.33         1\n          34       0.92      0.68      0.78        34\n          35       0.76      0.81      0.78        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.92      1.00      0.96        12\n          39       0.86      0.86      0.86         7\n          40       0.89      0.98      0.93        49\n          41       0.62      0.42      0.50        12\n          42       0.82      0.85      0.84        27\n          43       0.41      1.00      0.58         9\n          44       1.00      1.00      1.00         3\n          45       0.38      0.79      0.52        19\n          46       0.96      0.93      0.94       656\n          47       0.83      1.00      0.91         5\n          48       1.00      0.71      0.83         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.25      0.20      0.22         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          57       0.00      1.00      0.00         0\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.33      1.00      0.50         3\n          64       1.00      0.00      0.00         1\n          66       0.32      1.00      0.48        14\n          67       0.00      1.00      0.00         0\n          68       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       0.50      1.00      0.67         2\n          72       1.00      0.75      0.86         4\n          73       0.95      0.93      0.94       567\n          74       0.00      1.00      0.00         0\n          75       1.00      0.31      0.47        13\n          76       0.50      1.00      0.67         6\n          77       0.71      0.91      0.80        11\n          78       0.78      1.00      0.88        53\n          79       0.29      0.33      0.31         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          82       0.00      1.00      0.00         0\n          83       0.00      0.00      0.00         2\n          84       0.33      0.83      0.48         6\n          85       0.00      1.00      0.00         0\n          86       0.09      0.29      0.13         7\n          87       0.96      1.00      0.98        27\n          88       0.78      1.00      0.88         7\n          89       0.67      1.00      0.80         2\n          90       0.75      0.75      0.75        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.59      0.42      0.49        24\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.16      0.83      0.27         6\n         103       0.69      0.45      0.55        20\n         104       0.92      0.88      0.90       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         107       0.00      1.00      0.00         0\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.97      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.31      1.00      0.48         5\n         116       0.92      0.71      0.80       132\n         117       0.67      1.00      0.80         2\n         118       0.73      1.00      0.84         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.52      0.79      0.51     10056\nweighted avg       0.96      0.93      0.94     10056\n']",1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
Conv1D_128,"{'name': 'sequential_8', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_5'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_5', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_2', 'trainable': True, 'dtype': 'float32', 'filters': 128, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_5', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9808199405670166,0.2620179057121277,0.9761525392532349,0.2273818850517273,2448.0,567.5,500.0,437.0,4686.5,0.5148450920174529,"['              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.98      1702\n           1       0.50      1.00      0.67         2\n           2       0.95      0.95      0.95        20\n           3       0.99      0.99      0.99       101\n           4       0.80      1.00      0.89         8\n           5       0.38      0.60      0.46         5\n           6       0.00      0.00      0.00         1\n           7       0.21      0.80      0.33        10\n           8       0.33      0.67      0.44         3\n           9       0.40      0.67      0.50         3\n          10       0.00      1.00      0.00         0\n          11       0.50      0.33      0.40         3\n          12       0.00      1.00      0.00         0\n          13       0.11      0.29      0.16         7\n          14       1.00      0.20      0.33         5\n          15       0.42      0.91      0.57        11\n          16       0.43      0.91      0.59        11\n          17       0.44      0.85      0.58        46\n          18       1.00      0.97      0.98        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.80      1.00      0.89        12\n          25       0.95      0.60      0.73       102\n          26       0.90      0.90      0.90        39\n          27       0.83      0.87      0.85        39\n          28       0.92      0.92      0.92        12\n          29       0.33      1.00      0.50         1\n          30       0.00      0.00      0.00         1\n          31       0.70      0.78      0.74         9\n          32       0.88      0.62      0.72        68\n          33       0.20      1.00      0.33         1\n          34       0.94      0.44      0.60        34\n          35       0.88      0.71      0.79        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       1.00      1.00      1.00        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       0.42      0.42      0.42        12\n          42       0.83      0.93      0.88        27\n          43       0.47      1.00      0.64         9\n          44       0.75      1.00      0.86         3\n          45       0.47      0.84      0.60        19\n          46       0.96      0.94      0.95       656\n          47       1.00      1.00      1.00         5\n          48       0.75      0.86      0.80         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.11      0.20      0.14         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          59       0.00      1.00      0.00         0\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.33      1.00      0.50         3\n          64       1.00      0.00      0.00         1\n          66       0.43      0.21      0.29        14\n          68       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       1.00      0.75      0.86         4\n          73       0.96      0.92      0.94       567\n          74       0.00      1.00      0.00         0\n          75       1.00      0.54      0.70        13\n          76       0.67      0.67      0.67         6\n          77       0.91      0.91      0.91        11\n          78       0.87      0.98      0.92        53\n          79       0.17      0.33      0.22         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          83       1.00      0.00      0.00         2\n          84       0.29      0.83      0.43         6\n          85       0.00      1.00      0.00         0\n          86       0.06      0.57      0.11         7\n          87       1.00      1.00      1.00        27\n          88       0.78      1.00      0.88         7\n          89       1.00      1.00      1.00         2\n          90       0.90      0.75      0.82        12\n          91       0.00      1.00      0.00         0\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.58      0.29      0.39        24\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.18      1.00      0.30         6\n         103       0.64      0.45      0.53        20\n         104       0.95      0.85      0.90       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.97      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.31      1.00      0.48         5\n         116       0.92      0.42      0.58       132\n         117       0.67      1.00      0.80         2\n         118       0.67      1.00      0.80         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.55      0.78      0.53     10056\nweighted avg       0.96      0.93      0.94     10056\n', '              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.50      1.00      0.67         2\n           2       0.95      0.95      0.95        20\n           3       0.99      0.99      0.99       101\n           4       0.57      1.00      0.73         8\n           5       0.31      1.00      0.48         5\n           6       1.00      0.00      0.00         1\n           7       0.22      0.70      0.33        10\n           8       0.75      1.00      0.86         3\n           9       0.33      0.67      0.44         3\n          11       0.40      0.67      0.50         3\n          12       0.00      1.00      0.00         0\n          13       0.12      0.29      0.17         7\n          14       0.50      0.80      0.62         5\n          15       0.53      0.73      0.62        11\n          16       0.44      0.73      0.55        11\n          17       0.44      0.50      0.47        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.85      0.92      0.88        12\n          25       0.96      0.66      0.78       102\n          26       0.92      0.90      0.91        39\n          27       0.85      0.87      0.86        39\n          28       0.92      0.92      0.92        12\n          29       0.50      1.00      0.67         1\n          30       0.00      0.00      0.00         1\n          31       0.78      0.78      0.78         9\n          32       0.83      0.63      0.72        68\n          33       0.00      0.00      0.00         1\n          34       0.85      0.68      0.75        34\n          35       0.83      0.81      0.82        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       1.00      1.00      1.00        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       0.62      0.42      0.50        12\n          42       0.81      0.93      0.86        27\n          43       0.41      1.00      0.58         9\n          44       0.75      1.00      0.86         3\n          45       0.43      0.53      0.48        19\n          46       0.96      0.94      0.95       656\n          47       1.00      0.40      0.57         5\n          48       0.75      0.86      0.80         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.33      0.20      0.25         5\n          53       0.00      1.00      0.00         0\n          54       0.80      0.67      0.73         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.23      1.00      0.38         3\n          64       1.00      0.00      0.00         1\n          66       0.32      1.00      0.48        14\n          67       0.00      1.00      0.00         0\n          70       0.00      1.00      0.00         0\n          71       0.67      1.00      0.80         2\n          72       1.00      0.75      0.86         4\n          73       0.96      0.92      0.94       567\n          74       0.00      1.00      0.00         0\n          75       1.00      0.31      0.47        13\n          76       0.67      0.67      0.67         6\n          77       0.91      0.91      0.91        11\n          78       0.82      1.00      0.90        53\n          79       0.38      0.83      0.53         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          82       0.00      1.00      0.00         0\n          83       1.00      0.00      0.00         2\n          84       0.00      0.00      0.00         6\n          85       0.00      1.00      0.00         0\n          86       0.07      0.71      0.12         7\n          87       1.00      1.00      1.00        27\n          88       0.58      1.00      0.74         7\n          89       1.00      1.00      1.00         2\n          90       1.00      0.75      0.86        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.60      0.62      0.61        24\n          96       0.00      1.00      0.00         0\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.22      0.83      0.34         6\n         103       0.64      0.45      0.53        20\n         104       0.96      0.85      0.90       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.97      0.98      0.97        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.50      0.80      0.62         5\n         116       0.89      0.48      0.62       132\n         117       1.00      1.00      1.00         2\n         118       0.67      1.00      0.80         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.56      0.77      0.54     10056\nweighted avg       0.96      0.94      0.95     10056\n']",1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
Conv1D_256,"{'name': 'sequential_11', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_7'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_7', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d_3', 'trainable': True, 'dtype': 'float32', 'filters': 256, 'kernel_size': (3,), 'strides': (1,), 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': (1,), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_7', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9821685552597046,0.2653707265853882,0.9765644669532776,0.22874313592910767,2390.0,604.0,558.0,403.5,5037.0,0.5161756693367686,"['              precision    recall  f1-score   support\n\n           0       0.98      0.99      0.99      1702\n           1       1.00      1.00      1.00         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.50      0.40      0.44         5\n           6       0.00      0.00      0.00         1\n           7       0.19      0.70      0.30        10\n           8       0.50      1.00      0.67         3\n           9       0.50      1.00      0.67         3\n          11       0.50      0.33      0.40         3\n          12       0.00      1.00      0.00         0\n          13       0.16      0.57      0.25         7\n          14       0.40      0.80      0.53         5\n          15       0.42      1.00      0.59        11\n          16       0.47      0.82      0.60        11\n          17       0.37      0.57      0.45        46\n          18       0.97      1.00      0.99        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.80      1.00      0.89        12\n          25       0.93      0.61      0.73       102\n          26       0.89      0.85      0.87        39\n          27       0.87      0.87      0.87        39\n          28       0.92      0.92      0.92        12\n          29       0.33      1.00      0.50         1\n          30       0.00      0.00      0.00         1\n          31       0.78      0.78      0.78         9\n          32       0.87      0.50      0.64        68\n          33       0.00      0.00      0.00         1\n          34       0.94      0.47      0.63        34\n          35       0.85      0.71      0.77        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       1.00      1.00      1.00        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       0.50      0.42      0.45        12\n          42       0.79      0.85      0.82        27\n          43       0.60      1.00      0.75         9\n          44       1.00      1.00      1.00         3\n          45       0.23      0.84      0.36        19\n          46       0.96      0.88      0.92       656\n          47       1.00      1.00      1.00         5\n          48       1.00      0.57      0.73         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.25      0.20      0.22         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       1.00      0.00      0.00         3\n          64       1.00      0.00      0.00         1\n          66       0.33      1.00      0.50        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.05      1.00      0.09         4\n          73       0.95      0.77      0.85       567\n          74       0.00      1.00      0.00         0\n          75       0.81      1.00      0.90        13\n          76       0.38      1.00      0.55         6\n          77       1.00      1.00      1.00        11\n          78       0.88      0.98      0.93        53\n          79       0.23      0.50      0.32         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          82       0.00      1.00      0.00         0\n          83       1.00      0.00      0.00         2\n          84       0.27      0.67      0.38         6\n          85       0.00      1.00      0.00         0\n          86       0.07      0.71      0.13         7\n          87       1.00      1.00      1.00        27\n          88       0.88      1.00      0.93         7\n          89       1.00      1.00      1.00         2\n          90       0.90      0.75      0.82        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.56      0.38      0.45        24\n          96       0.00      1.00      0.00         0\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.20      0.83      0.32         6\n         103       0.64      0.45      0.53        20\n         104       0.94      0.86      0.90       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.98      0.98      0.98        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         115       0.33      1.00      0.50         5\n         116       0.92      0.43      0.59       132\n         117       1.00      1.00      1.00         2\n         118       0.73      1.00      0.84         8\n         119       0.99      0.97      0.98      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.56      0.78      0.54     10056\nweighted avg       0.96      0.93      0.94     10056\n', '              precision    recall  f1-score   support\n\n           0       0.98      1.00      0.99      1702\n           1       1.00      1.00      1.00         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.62      1.00      0.76         8\n           5       0.67      0.40      0.50         5\n           6       0.00      0.00      0.00         1\n           7       0.17      0.70      0.27        10\n           8       0.50      1.00      0.67         3\n           9       0.43      1.00      0.60         3\n          11       0.67      0.67      0.67         3\n          12       0.00      1.00      0.00         0\n          13       0.14      0.43      0.21         7\n          14       0.43      0.60      0.50         5\n          15       0.53      0.82      0.64        11\n          16       0.41      0.82      0.55        11\n          17       0.62      0.52      0.56        46\n          18       1.00      0.97      0.98        33\n          19       0.75      1.00      0.86         6\n          20       1.00      1.00      1.00        61\n          21       0.00      1.00      0.00         0\n          24       0.79      0.92      0.85        12\n          25       0.93      0.64      0.76       102\n          26       0.86      0.82      0.84        39\n          27       0.92      0.87      0.89        39\n          28       0.92      0.92      0.92        12\n          29       0.33      1.00      0.50         1\n          30       0.00      0.00      0.00         1\n          31       0.67      0.67      0.67         9\n          32       0.89      0.60      0.72        68\n          33       0.00      0.00      0.00         1\n          34       0.88      0.68      0.77        34\n          35       0.85      0.71      0.77        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       1.00      1.00      1.00        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       0.62      0.42      0.50        12\n          42       0.83      0.93      0.88        27\n          43       0.82      1.00      0.90         9\n          44       1.00      1.00      1.00         3\n          45       0.59      0.84      0.70        19\n          46       0.96      0.95      0.95       656\n          47       1.00      1.00      1.00         5\n          48       0.75      0.86      0.80         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.12      0.20      0.15         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       1.00      0.83      0.91         6\n          59       0.00      1.00      0.00         0\n          61       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.33      1.00      0.50         3\n          64       1.00      0.00      0.00         1\n          65       0.00      1.00      0.00         0\n          66       0.34      1.00      0.51        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.50      1.00      0.67         4\n          73       0.95      0.94      0.95       567\n          74       0.00      1.00      0.00         0\n          75       1.00      0.54      0.70        13\n          76       0.67      0.67      0.67         6\n          77       0.92      1.00      0.96        11\n          78       0.80      0.98      0.88        53\n          79       0.40      0.33      0.36         6\n          80       0.00      1.00      0.00         0\n          81       0.00      0.00      0.00         2\n          82       0.00      1.00      0.00         0\n          83       1.00      0.00      0.00         2\n          84       0.27      0.67      0.38         6\n          85       0.00      1.00      0.00         0\n          86       0.07      0.71      0.14         7\n          87       1.00      1.00      1.00        27\n          88       0.88      1.00      0.93         7\n          89       1.00      1.00      1.00         2\n          90       0.82      0.75      0.78        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.57      0.33      0.42        24\n          96       0.00      1.00      0.00         0\n          97       0.50      1.00      0.67         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.29      0.83      0.43         6\n         103       0.60      0.45      0.51        20\n         104       0.88      0.90      0.89       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         109       0.00      1.00      0.00         0\n         111       0.98      0.98      0.98        58\n         112       0.00      1.00      0.00         0\n         113       0.00      1.00      0.00         0\n         114       0.00      1.00      0.00         0\n         115       0.31      1.00      0.48         5\n         116       0.93      0.39      0.55       132\n         117       0.67      1.00      0.80         2\n         118       0.73      1.00      0.84         8\n         119       0.99      0.97      0.98      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.55      0.78      0.54     10056\nweighted avg       0.96      0.94      0.95     10056\n']",1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
