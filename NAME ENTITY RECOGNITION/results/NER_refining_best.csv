architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
LSTM_128_01,"{'name': 'sequential_2', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'lstm_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9748011231422424,0.272163987159729,0.9693424701690674,0.2450362741947174,2595.0,978.0,353.0,1085.0,6013.0,0.6325256190877446,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.40      1.00      0.57         2\n           2       0.74      1.00      0.85        20\n           3       0.97      0.97      0.97       101\n           4       0.89      1.00      0.94         8\n           5       0.14      1.00      0.25         5\n           6       1.00      1.00      1.00         1\n           7       0.62      1.00      0.77        10\n           8       1.00      1.00      1.00         3\n           9       0.43      1.00      0.60         3\n          11       0.43      1.00      0.60         3\n          13       0.88      1.00      0.93         7\n          14       0.44      0.80      0.57         5\n          15       1.00      1.00      1.00        11\n          16       0.38      1.00      0.55        11\n          17       0.22      0.72      0.34        46\n          18       0.76      0.97      0.85        33\n          19       0.86      1.00      0.92         6\n          20       0.75      1.00      0.86        61\n          21       0.00      1.00      0.00         0\n          22       0.00      1.00      0.00         0\n          24       0.92      0.92      0.92        12\n          25       0.93      0.97      0.95       102\n          26       0.95      0.90      0.92        39\n          27       0.84      0.97      0.90        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.50      0.67      0.57         9\n          32       0.87      0.81      0.84        68\n          33       1.00      1.00      1.00         1\n          34       0.93      0.79      0.86        34\n          35       0.90      0.84      0.87        31\n          36       0.62      1.00      0.77         5\n          37       0.11      0.50      0.18         2\n          38       0.44      1.00      0.62        12\n          39       0.86      0.86      0.86         7\n          40       0.88      0.86      0.87        49\n          41       0.50      0.42      0.45        12\n          42       0.77      0.85      0.81        27\n          43       0.11      0.89      0.19         9\n          44       1.00      1.00      1.00         3\n          45       0.27      0.79      0.41        19\n          46       0.96      0.93      0.95       656\n          47       1.00      0.80      0.89         5\n          48       0.78      1.00      0.88         7\n          49       0.71      1.00      0.83         5\n          50       0.00      0.00      0.00         1\n          51       0.67      0.86      0.75         7\n          52       0.11      0.40      0.17         5\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.93      0.97      0.95        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.30      1.00      0.46        14\n          68       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.11      0.75      0.19         4\n          73       0.84      0.95      0.89       567\n          74       0.00      1.00      0.00         0\n          75       0.81      1.00      0.90        13\n          76       0.67      1.00      0.80         6\n          77       0.61      1.00      0.76        11\n          78       0.60      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.47      1.00      0.64         7\n          87       0.84      1.00      0.92        27\n          88       0.32      1.00      0.48         7\n          89       1.00      1.00      1.00         2\n          90       0.61      0.92      0.73        12\n          93       0.50      1.00      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.77      0.96      0.85        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.12      0.50      0.20         2\n         102       0.43      1.00      0.60         6\n         103       0.80      0.80      0.80        20\n         104       0.95      0.95      0.95       110\n         105       1.00      0.50      0.67         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.78      0.98      0.87        58\n         115       0.36      1.00      0.53         5\n         116       0.94      0.98      0.96       132\n         117       0.40      1.00      0.57         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.88      0.93      5640\n\n    accuracy                           0.91     10056\n   macro avg       0.62      0.89      0.66     10056\nweighted avg       0.95      0.91      0.93     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_64_01,"{'name': 'sequential_4', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_1', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_1', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9762191772460938,0.27559444308280945,0.9728564620018005,0.24865084886550903,2672.0,677.0,276.0,830.0,4555.0,0.6342337041513971,['              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98      1702\n           1       0.33      1.00      0.50         2\n           2       0.77      1.00      0.87        20\n           3       0.93      0.99      0.96       101\n           4       0.57      1.00      0.73         8\n           5       0.33      1.00      0.50         5\n           6       1.00      1.00      1.00         1\n           7       0.77      1.00      0.87        10\n           8       0.43      1.00      0.60         3\n           9       0.60      1.00      0.75         3\n          11       0.60      1.00      0.75         3\n          13       0.67      0.86      0.75         7\n          14       0.17      0.40      0.24         5\n          15       0.85      1.00      0.92        11\n          16       0.61      1.00      0.76        11\n          17       0.30      0.83      0.44        46\n          18       0.97      1.00      0.99        33\n          19       0.86      1.00      0.92         6\n          20       0.98      1.00      0.99        61\n          24       0.86      1.00      0.92        12\n          25       0.97      0.98      0.98       102\n          26       0.92      0.87      0.89        39\n          27       0.88      0.92      0.90        39\n          28       0.73      0.92      0.81        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.62      0.89      0.73         9\n          32       0.75      0.84      0.79        68\n          33       0.17      1.00      0.29         1\n          34       0.96      0.76      0.85        34\n          35       0.96      0.87      0.92        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.34      1.00      0.51        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       0.83      0.42      0.56        12\n          42       0.79      0.85      0.82        27\n          43       0.31      1.00      0.47         9\n          44       0.75      1.00      0.86         3\n          45       0.36      0.84      0.51        19\n          46       0.94      0.96      0.95       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       0.83      1.00      0.91         5\n          50       0.20      1.00      0.33         1\n          51       0.55      0.86      0.67         7\n          52       0.23      0.60      0.33         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.43      1.00      0.60         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.38      1.00      0.55        14\n          71       1.00      1.00      1.00         2\n          72       0.22      1.00      0.36         4\n          73       0.94      0.96      0.95       567\n          75       1.00      1.00      1.00        13\n          76       0.46      1.00      0.63         6\n          77       0.45      0.91      0.61        11\n          78       0.58      0.98      0.73        53\n          79       0.86      1.00      0.92         6\n          80       0.00      1.00      0.00         0\n          81       0.67      1.00      0.80         2\n          82       0.00      1.00      0.00         0\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          85       0.00      1.00      0.00         0\n          86       0.44      1.00      0.61         7\n          87       1.00      1.00      1.00        27\n          88       0.64      1.00      0.78         7\n          89       0.33      1.00      0.50         2\n          90       0.85      0.92      0.88        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.88      0.92      0.90        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.08      0.50      0.14         2\n         102       0.36      0.67      0.47         6\n         103       0.68      0.75      0.71        20\n         104       0.95      0.96      0.95       110\n         105       0.67      1.00      0.80         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.98      0.98       132\n         117       0.67      1.00      0.80         2\n         118       0.40      1.00      0.57         8\n         119       0.99      0.91      0.95      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.62      0.90      0.66     10056\nweighted avg       0.96      0.93      0.94     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_128_01,"{'name': 'sequential_6', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_2'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_2', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_1', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_2', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9813048839569092,0.27906957268714905,0.9776064157485962,0.25583499670028687,2670.0,563.0,278.0,702.0,4212.0,0.6766794386287722,['              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98      1702\n           1       0.29      1.00      0.44         2\n           2       0.90      0.95      0.93        20\n           3       0.98      0.98      0.98       101\n           4       0.62      1.00      0.76         8\n           5       0.36      1.00      0.53         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.75      1.00      0.86         3\n           9       0.60      1.00      0.75         3\n          11       0.75      1.00      0.86         3\n          13       0.64      1.00      0.78         7\n          14       0.30      0.60      0.40         5\n          15       1.00      0.91      0.95        11\n          16       0.79      1.00      0.88        11\n          17       0.37      0.87      0.52        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.92      1.00      0.96        12\n          25       0.99      0.98      0.99       102\n          26       0.90      0.90      0.90        39\n          27       0.86      0.95      0.90        39\n          28       0.79      0.92      0.85        12\n          29       0.50      1.00      0.67         1\n          30       0.33      1.00      0.50         1\n          31       0.73      0.89      0.80         9\n          32       0.89      0.87      0.88        68\n          33       0.12      1.00      0.22         1\n          34       0.93      0.79      0.86        34\n          35       0.93      0.90      0.92        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.34      1.00      0.51        12\n          39       0.86      0.86      0.86         7\n          40       0.89      0.98      0.93        49\n          41       0.56      0.42      0.48        12\n          42       0.79      0.85      0.82        27\n          43       0.50      1.00      0.67         9\n          44       1.00      1.00      1.00         3\n          45       0.42      0.84      0.56        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       1.00      0.00      0.00         1\n          51       0.60      0.86      0.71         7\n          52       0.43      0.60      0.50         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.93      0.98      0.95        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.46      0.93      0.62        14\n          71       1.00      1.00      1.00         2\n          72       0.40      1.00      0.57         4\n          73       0.92      0.96      0.94       567\n          75       1.00      1.00      1.00        13\n          76       0.86      1.00      0.92         6\n          77       0.48      1.00      0.65        11\n          78       0.63      0.98      0.76        53\n          79       0.86      1.00      0.92         6\n          81       0.67      1.00      0.80         2\n          83       0.33      0.50      0.40         2\n          84       1.00      1.00      1.00         6\n          86       0.44      1.00      0.61         7\n          87       1.00      1.00      1.00        27\n          88       1.00      1.00      1.00         7\n          89       0.50      1.00      0.67         2\n          90       0.65      0.92      0.76        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.81      0.92      0.86        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.33      0.67      0.44         6\n         103       0.74      0.85      0.79        20\n         104       0.95      0.96      0.95       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.81      0.98      0.89        58\n         113       0.00      1.00      0.00         0\n         115       0.71      1.00      0.83         5\n         116       0.96      0.98      0.97       132\n         117       1.00      1.00      1.00         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.93      0.96      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.66      0.90      0.69     10056\nweighted avg       0.96      0.94      0.95     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_128_02,"{'name': 'sequential_8', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_3'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_3', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_2', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_3', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9742732644081116,0.27679941058158875,0.9749889969825745,0.2515747845172882,2679.0,601.0,269.0,746.0,4585.0,0.6574926064917045,['              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98      1702\n           1       0.50      1.00      0.67         2\n           2       0.87      1.00      0.93        20\n           3       0.98      0.99      0.99       101\n           4       0.53      1.00      0.70         8\n           5       0.42      1.00      0.59         5\n           6       1.00      1.00      1.00         1\n           7       0.71      1.00      0.83        10\n           8       0.43      1.00      0.60         3\n           9       0.60      1.00      0.75         3\n          11       0.50      0.67      0.57         3\n          13       0.50      0.86      0.63         7\n          14       0.43      0.60      0.50         5\n          15       0.91      0.91      0.91        11\n          16       0.85      1.00      0.92        11\n          17       0.45      0.89      0.60        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       0.95      1.00      0.98        61\n          22       0.00      1.00      0.00         0\n          24       1.00      1.00      1.00        12\n          25       0.98      0.98      0.98       102\n          26       0.90      0.92      0.91        39\n          27       0.84      0.95      0.89        39\n          28       0.79      0.92      0.85        12\n          29       0.50      1.00      0.67         1\n          30       0.17      1.00      0.29         1\n          31       0.64      0.78      0.70         9\n          32       0.83      0.87      0.85        68\n          33       0.50      1.00      0.67         1\n          34       0.91      0.85      0.88        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.38      1.00      0.55        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       0.71      0.42      0.53        12\n          42       0.77      0.89      0.83        27\n          43       0.64      1.00      0.78         9\n          44       0.75      1.00      0.86         3\n          45       0.40      0.84      0.54        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       0.88      1.00      0.93         7\n          49       0.83      1.00      0.91         5\n          50       1.00      0.00      0.00         1\n          51       0.55      0.86      0.67         7\n          52       0.33      0.60      0.43         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.40      1.00      0.57        14\n          68       0.00      1.00      0.00         0\n          71       0.67      1.00      0.80         2\n          72       0.25      1.00      0.40         4\n          73       0.92      0.97      0.94       567\n          74       0.00      1.00      0.00         0\n          75       0.93      1.00      0.96        13\n          76       0.67      1.00      0.80         6\n          77       0.50      1.00      0.67        11\n          78       0.62      0.98      0.76        53\n          79       0.86      1.00      0.92         6\n          81       0.50      0.50      0.50         2\n          83       0.50      0.50      0.50         2\n          84       0.86      1.00      0.92         6\n          86       0.41      1.00      0.58         7\n          87       0.93      1.00      0.96        27\n          88       0.50      1.00      0.67         7\n          89       0.33      1.00      0.50         2\n          90       0.58      0.92      0.71        12\n          92       0.00      1.00      0.00         0\n          93       0.50      0.50      0.50         2\n          95       0.82      0.96      0.88        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.29      0.67      0.40         6\n         103       0.74      0.85      0.79        20\n         104       0.95      0.96      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.83      0.98      0.90        58\n         115       0.71      1.00      0.83         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.42      1.00      0.59         8\n         119       0.99      0.92      0.95      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.63      0.88      0.67     10056\nweighted avg       0.96      0.94      0.95     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_256_01,"{'name': 'sequential_10', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_4'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_4', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_3', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_5', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_4', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9783036708831787,0.27729034423828125,0.9760796427726746,0.25248223543167114,2690.0,598.0,258.0,750.0,4254.0,0.6663704505668581,['              precision    recall  f1-score   support\n\n           0       0.99      0.97      0.98      1702\n           1       0.33      1.00      0.50         2\n           2       0.83      1.00      0.91        20\n           3       0.98      0.98      0.98       101\n           4       0.36      1.00      0.53         8\n           5       0.42      1.00      0.59         5\n           6       1.00      1.00      1.00         1\n           7       0.62      1.00      0.77        10\n           8       0.75      1.00      0.86         3\n           9       0.75      1.00      0.86         3\n          11       0.75      1.00      0.86         3\n          13       0.88      1.00      0.93         7\n          14       0.30      0.60      0.40         5\n          15       0.92      1.00      0.96        11\n          16       0.73      1.00      0.85        11\n          17       0.39      0.85      0.53        46\n          18       0.92      1.00      0.96        33\n          19       0.86      1.00      0.92         6\n          20       0.98      1.00      0.99        61\n          22       0.00      1.00      0.00         0\n          24       0.92      1.00      0.96        12\n          25       0.97      0.98      0.98       102\n          26       0.92      0.90      0.91        39\n          27       0.84      0.95      0.89        39\n          28       0.73      0.92      0.81        12\n          29       1.00      1.00      1.00         1\n          30       0.25      1.00      0.40         1\n          31       0.50      0.78      0.61         9\n          32       0.80      0.90      0.85        68\n          33       0.25      1.00      0.40         1\n          34       0.94      0.85      0.89        34\n          35       0.91      0.94      0.92        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.39      1.00      0.56        12\n          39       0.86      0.86      0.86         7\n          40       0.92      0.98      0.95        49\n          41       1.00      0.42      0.59        12\n          42       0.82      0.85      0.84        27\n          43       0.36      1.00      0.53         9\n          44       1.00      1.00      1.00         3\n          45       0.49      0.89      0.63        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       0.71      1.00      0.83         5\n          50       1.00      0.00      0.00         1\n          51       0.55      0.86      0.67         7\n          52       0.20      0.40      0.27         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.47      1.00      0.64        14\n          71       0.33      1.00      0.50         2\n          72       0.33      1.00      0.50         4\n          73       0.93      0.96      0.95       567\n          75       0.93      1.00      0.96        13\n          76       0.67      1.00      0.80         6\n          77       0.48      1.00      0.65        11\n          78       0.60      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.33      0.50      0.40         2\n          84       1.00      1.00      1.00         6\n          86       0.37      1.00      0.54         7\n          87       1.00      1.00      1.00        27\n          88       0.44      1.00      0.61         7\n          89       0.50      1.00      0.67         2\n          90       0.73      0.92      0.81        12\n          92       0.00      1.00      0.00         0\n          93       1.00      0.50      0.67         2\n          94       0.00      1.00      0.00         0\n          95       0.82      0.96      0.88        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         101       0.12      0.50      0.20         2\n         102       0.31      0.67      0.42         6\n         103       0.71      0.85      0.77        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.33      1.00      0.50         2\n         109       0.00      1.00      0.00         0\n         111       0.86      0.98      0.92        58\n         113       0.00      1.00      0.00         0\n         115       0.57      0.80      0.67         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.40      1.00      0.57         8\n         119       0.99      0.92      0.96      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.67      0.90      0.69     10056\nweighted avg       0.96      0.94      0.95     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_64_01,"{'name': 'sequential_12', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_5'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_5', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_4', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_6', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_5', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9849720597267151,0.28642284870147705,0.9800784587860107,0.2591326832771301,2643.0,481.0,305.0,640.0,4045.0,0.642029956097187,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.67      1.00      0.80         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.62      1.00      0.77        10\n           8       1.00      1.00      1.00         3\n           9       0.75      1.00      0.86         3\n          11       0.60      1.00      0.75         3\n          13       0.88      1.00      0.93         7\n          14       0.50      0.80      0.62         5\n          15       0.92      1.00      0.96        11\n          16       0.69      1.00      0.81        11\n          17       0.53      0.80      0.64        46\n          18       1.00      0.97      0.98        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.79      0.92      0.85        12\n          25       0.99      0.98      0.99       102\n          26       0.97      0.90      0.93        39\n          27       0.93      0.95      0.94        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.75      1.00      0.86         9\n          32       0.83      0.84      0.83        68\n          33       0.00      0.00      0.00         1\n          34       0.90      0.76      0.83        34\n          35       0.94      0.94      0.94        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.41      1.00      0.59        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       1.00      0.42      0.59        12\n          42       0.72      0.85      0.78        27\n          43       0.36      1.00      0.53         9\n          44       1.00      1.00      1.00         3\n          45       0.83      0.79      0.81        19\n          46       0.97      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       0.88      1.00      0.93         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.17      0.40      0.24         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       0.67      0.67      0.67         3\n          64       1.00      1.00      1.00         1\n          66       0.62      0.93      0.74        14\n          67       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.50      1.00      0.67         4\n          73       0.95      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.67      1.00      0.80         6\n          77       0.79      1.00      0.88        11\n          78       0.61      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.25      0.50      0.33         2\n          84       1.00      1.00      1.00         6\n          86       0.54      1.00      0.70         7\n          87       1.00      1.00      1.00        27\n          88       0.35      1.00      0.52         7\n          89       0.10      1.00      0.17         2\n          90       0.61      0.92      0.73        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.81      0.92      0.86        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.29      0.83      0.43         6\n         103       0.70      0.70      0.70        20\n         104       0.95      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         109       0.00      1.00      0.00         0\n         111       0.89      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.96      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.50      1.00      0.67         8\n         119       0.99      0.93      0.96      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.64      0.89      0.68     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_01,"{'name': 'sequential_14', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_6'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_6', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_5', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_7', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_6', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9892316460609436,0.29278939962387085,0.9838349223136902,0.26476553082466125,2675.0,382.0,273.0,524.0,3194.0,0.6682323359697008,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.50      1.00      0.67         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.62      1.00      0.76         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       1.00      0.67      0.80         3\n           9       1.00      0.67      0.80         3\n          11       0.60      1.00      0.75         3\n          13       0.78      1.00      0.88         7\n          14       0.50      0.80      0.62         5\n          15       0.85      1.00      0.92        11\n          16       0.58      1.00      0.73        11\n          17       0.78      0.87      0.82        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          23       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.95      0.95      0.95        39\n          27       0.90      0.95      0.93        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.25      1.00      0.40         1\n          31       0.69      1.00      0.82         9\n          32       0.94      0.85      0.89        68\n          33       0.50      1.00      0.67         1\n          34       1.00      0.79      0.89        34\n          35       0.88      0.90      0.89        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.67      1.00      0.80        12\n          39       0.86      0.86      0.86         7\n          40       0.96      0.98      0.97        49\n          41       1.00      0.42      0.59        12\n          42       0.77      0.85      0.81        27\n          43       0.53      1.00      0.69         9\n          44       1.00      1.00      1.00         3\n          45       0.71      0.79      0.75        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.50      1.00      0.67         1\n          51       0.86      0.86      0.86         7\n          52       0.33      0.40      0.36         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.67      0.67      0.67         3\n          64       1.00      0.00      0.00         1\n          66       0.93      0.93      0.93        14\n          67       0.00      1.00      0.00         0\n          68       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.44      1.00      0.62         4\n          73       0.96      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.75      1.00      0.86         6\n          77       0.79      1.00      0.88        11\n          78       0.74      0.98      0.85        53\n          79       0.75      1.00      0.86         6\n          81       0.50      1.00      0.67         2\n          83       0.17      0.50      0.25         2\n          84       0.86      1.00      0.92         6\n          86       0.64      1.00      0.78         7\n          87       1.00      1.00      1.00        27\n          88       0.54      1.00      0.70         7\n          89       0.67      1.00      0.80         2\n          90       0.85      0.92      0.88        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.85      0.92      0.88        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.10      0.50      0.17         2\n         102       0.26      0.83      0.40         6\n         103       0.68      0.65      0.67        20\n         104       0.96      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.90      0.98      0.94        58\n         113       0.00      1.00      0.00         0\n         115       0.50      1.00      0.67         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.40      1.00      0.57         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.66      0.91      0.69     10056\nweighted avg       0.97      0.96      0.96     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_02,"{'name': 'sequential_16', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_7'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_7', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_6', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_8', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_7', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9875469207763672,0.29118189215660095,0.9819204807281494,0.26403293013572693,2682.0,400.0,266.0,559.0,3291.0,0.7004676173733151,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.91      1.00      0.95        20\n           3       0.99      0.98      0.99       101\n           4       1.00      1.00      1.00         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.77      1.00      0.87        10\n           8       1.00      0.67      0.80         3\n           9       0.50      0.67      0.57         3\n          11       0.43      1.00      0.60         3\n          13       0.64      1.00      0.78         7\n          14       0.57      0.80      0.67         5\n          15       1.00      0.91      0.95        11\n          16       0.65      1.00      0.79        11\n          17       0.46      0.83      0.59        46\n          18       1.00      0.97      0.98        33\n          19       0.86      1.00      0.92         6\n          20       0.98      1.00      0.99        61\n          24       0.92      1.00      0.96        12\n          25       0.99      0.97      0.98       102\n          26       0.92      0.92      0.92        39\n          27       0.90      0.97      0.94        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.33      1.00      0.50         1\n          31       0.73      0.89      0.80         9\n          32       0.93      0.84      0.88        68\n          33       0.50      1.00      0.67         1\n          34       0.97      0.85      0.91        34\n          35       0.94      0.94      0.94        31\n          36       1.00      1.00      1.00         5\n          37       0.33      0.50      0.40         2\n          38       0.92      1.00      0.96        12\n          39       0.86      0.86      0.86         7\n          40       0.89      0.98      0.93        49\n          41       0.71      0.42      0.53        12\n          42       0.79      0.85      0.82        27\n          43       0.36      1.00      0.53         9\n          44       1.00      1.00      1.00         3\n          45       0.74      0.89      0.81        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       1.00      0.00      0.00         1\n          51       0.75      0.86      0.80         7\n          52       0.18      0.40      0.25         5\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          60       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.82      1.00      0.90        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.44      1.00      0.62         4\n          73       0.96      0.96      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.75      1.00      0.86         6\n          77       0.85      1.00      0.92        11\n          78       0.68      0.98      0.80        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          85       0.00      1.00      0.00         0\n          86       0.44      1.00      0.61         7\n          87       1.00      1.00      1.00        27\n          88       0.37      1.00      0.54         7\n          89       1.00      1.00      1.00         2\n          90       0.73      0.92      0.81        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          95       0.77      0.96      0.85        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.19      0.83      0.31         6\n         103       0.70      0.70      0.70        20\n         104       0.95      0.96      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         115       0.56      1.00      0.71         5\n         116       0.96      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.94      0.97      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.70      0.89      0.72     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_256_01,"{'name': 'sequential_18', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_8'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_8', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_7', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_6', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_6', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_9', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_8', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9780580997467041,0.27529504895210266,0.9760312438011169,0.25135213136672974,2683.0,578.0,265.0,737.0,4483.0,0.6743707015060565,['              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.98      1702\n           1       0.67      1.00      0.80         2\n           2       0.87      1.00      0.93        20\n           3       0.98      0.99      0.99       101\n           4       0.67      1.00      0.80         8\n           5       0.45      1.00      0.62         5\n           6       1.00      1.00      1.00         1\n           7       0.71      1.00      0.83        10\n           8       0.50      1.00      0.67         3\n           9       0.75      1.00      0.86         3\n          11       0.50      1.00      0.67         3\n          13       0.70      1.00      0.82         7\n          14       0.36      0.80      0.50         5\n          15       0.85      1.00      0.92        11\n          16       0.69      1.00      0.81        11\n          17       0.44      0.87      0.59        46\n          18       1.00      0.97      0.98        33\n          19       0.86      1.00      0.92         6\n          20       0.97      1.00      0.98        61\n          22       0.00      1.00      0.00         0\n          24       1.00      0.92      0.96        12\n          25       0.98      0.98      0.98       102\n          26       0.84      0.92      0.88        39\n          27       0.90      0.95      0.93        39\n          28       0.73      0.92      0.81        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.54      0.78      0.64         9\n          32       0.80      0.87      0.83        68\n          33       0.33      1.00      0.50         1\n          34       1.00      0.85      0.92        34\n          35       0.94      0.94      0.94        31\n          36       0.83      1.00      0.91         5\n          37       0.50      0.50      0.50         2\n          38       0.40      1.00      0.57        12\n          39       0.86      0.86      0.86         7\n          40       0.91      0.98      0.94        49\n          41       0.62      0.42      0.50        12\n          42       0.79      0.85      0.82        27\n          43       0.45      1.00      0.62         9\n          44       1.00      1.00      1.00         3\n          45       0.46      0.84      0.59        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.33      1.00      0.50         1\n          51       0.55      0.86      0.67         7\n          52       0.30      0.60      0.40         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.40      1.00      0.57        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.27      1.00      0.42         4\n          73       0.93      0.96      0.95       567\n          75       0.87      1.00      0.93        13\n          76       0.86      1.00      0.92         6\n          77       0.65      1.00      0.79        11\n          78       0.63      0.98      0.77        53\n          79       0.67      1.00      0.80         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       0.86      1.00      0.92         6\n          86       0.33      1.00      0.50         7\n          87       0.96      1.00      0.98        27\n          88       0.44      1.00      0.61         7\n          89       0.67      1.00      0.80         2\n          90       0.61      0.92      0.73        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.79      0.96      0.87        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.38      1.00      0.55         6\n         103       0.67      0.70      0.68        20\n         104       0.96      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.90      0.98      0.94        58\n         115       0.45      1.00      0.62         5\n         116       0.96      0.99      0.98       132\n         117       0.67      1.00      0.80         2\n         118       0.36      1.00      0.53         8\n         119       0.99      0.93      0.96      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.66      0.91      0.70     10056\nweighted avg       0.96      0.94      0.95     10056\n'],1000,1024,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
LSTM_128_01,"{'name': 'sequential_20', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_9'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_9', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'lstm_7', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': False, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_10', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_9', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_9', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9787514209747314,0.2780548930168152,0.9745528697967529,0.2499789148569107,2618.0,756.0,330.0,885.0,5262.0,0.6317952310856897,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.50      1.00      0.67         2\n           2       0.74      1.00      0.85        20\n           3       0.99      0.97      0.98       101\n           4       0.89      1.00      0.94         8\n           5       0.19      1.00      0.32         5\n           6       1.00      1.00      1.00         1\n           7       0.71      1.00      0.83        10\n           8       0.75      1.00      0.86         3\n           9       0.43      1.00      0.60         3\n          11       0.43      1.00      0.60         3\n          12       0.00      1.00      0.00         0\n          13       0.78      1.00      0.88         7\n          14       0.50      0.80      0.62         5\n          15       0.91      0.91      0.91        11\n          16       0.58      1.00      0.73        11\n          17       0.33      0.74      0.46        46\n          18       0.81      0.91      0.86        33\n          19       0.83      0.83      0.83         6\n          20       0.87      1.00      0.93        61\n          22       0.00      1.00      0.00         0\n          24       0.73      0.92      0.81        12\n          25       0.99      0.98      0.99       102\n          26       0.97      0.87      0.92        39\n          27       0.88      0.95      0.91        39\n          28       0.69      0.92      0.79        12\n          29       1.00      1.00      1.00         1\n          30       0.25      1.00      0.40         1\n          31       0.50      0.78      0.61         9\n          32       0.86      0.84      0.85        68\n          33       1.00      1.00      1.00         1\n          34       0.96      0.76      0.85        34\n          35       0.75      0.87      0.81        31\n          36       0.62      1.00      0.77         5\n          37       0.25      0.50      0.33         2\n          38       0.48      1.00      0.65        12\n          39       0.60      0.86      0.71         7\n          40       0.93      0.88      0.91        49\n          41       0.83      0.42      0.56        12\n          42       0.77      0.85      0.81        27\n          43       0.15      1.00      0.26         9\n          44       1.00      1.00      1.00         3\n          45       0.32      0.79      0.45        19\n          46       0.95      0.95      0.95       656\n          47       1.00      0.80      0.89         5\n          48       0.88      1.00      0.93         7\n          49       0.56      1.00      0.71         5\n          50       0.33      1.00      0.50         1\n          51       0.86      0.86      0.86         7\n          52       0.17      0.40      0.24         5\n          53       0.00      1.00      0.00         0\n          54       0.71      0.83      0.77         6\n          55       0.00      1.00      0.00         0\n          56       0.67      1.00      0.80         6\n          57       0.00      1.00      0.00         0\n          60       0.00      1.00      0.00         0\n          62       0.90      0.98      0.94        64\n          63       0.60      1.00      0.75         3\n          64       1.00      0.00      0.00         1\n          66       0.39      1.00      0.56        14\n          70       0.00      1.00      0.00         0\n          71       0.67      1.00      0.80         2\n          72       0.18      0.75      0.29         4\n          73       0.90      0.95      0.93       567\n          74       0.00      1.00      0.00         0\n          75       0.87      1.00      0.93        13\n          76       0.75      1.00      0.86         6\n          77       0.79      1.00      0.88        11\n          78       0.70      0.98      0.82        53\n          79       0.60      1.00      0.75         6\n          81       0.50      1.00      0.67         2\n          83       0.00      0.00      0.00         2\n          84       0.86      1.00      0.92         6\n          86       0.54      1.00      0.70         7\n          87       0.69      1.00      0.82        27\n          88       0.47      1.00      0.64         7\n          89       0.11      1.00      0.19         2\n          90       0.65      0.92      0.76        12\n          93       0.67      1.00      0.80         2\n          95       0.71      0.92      0.80        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.11      0.50      0.18         2\n         102       0.25      1.00      0.40         6\n         103       0.67      0.90      0.77        20\n         104       0.93      0.97      0.95       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.84      0.98      0.90        58\n         113       0.00      1.00      0.00         0\n         115       0.62      1.00      0.77         5\n         116       0.95      0.99      0.97       132\n         117       0.67      1.00      0.80         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.90      0.94      5640\n\n    accuracy                           0.93     10056\n   macro avg       0.61      0.90      0.65     10056\nweighted avg       0.96      0.93      0.94     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_64_01,"{'name': 'sequential_22', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_10'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_10', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_8', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_8', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_8', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_11', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_10', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_10', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9780157804489136,0.27725034952163696,0.9746983051300049,0.24815979599952698,2649.0,627.0,299.0,774.0,4694.0,0.6679549287655412,['              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99      1702\n           1       0.40      1.00      0.57         2\n           2       0.83      0.95      0.88        20\n           3       0.96      0.99      0.98       101\n           4       0.42      1.00      0.59         8\n           5       0.29      1.00      0.45         5\n           6       1.00      1.00      1.00         1\n           7       0.71      1.00      0.83        10\n           8       0.50      1.00      0.67         3\n           9       1.00      1.00      1.00         3\n          11       0.60      1.00      0.75         3\n          13       0.64      1.00      0.78         7\n          14       0.40      0.80      0.53         5\n          15       1.00      1.00      1.00        11\n          16       0.61      1.00      0.76        11\n          17       0.35      0.85      0.49        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          24       0.85      0.92      0.88        12\n          25       0.98      0.98      0.98       102\n          26       0.85      0.87      0.86        39\n          27       0.81      0.97      0.88        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.69      1.00      0.82         9\n          32       0.82      0.88      0.85        68\n          33       0.00      0.00      0.00         1\n          34       0.90      0.79      0.84        34\n          35       0.85      0.90      0.88        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.31      1.00      0.47        12\n          39       0.86      0.86      0.86         7\n          40       0.92      0.98      0.95        49\n          41       0.62      0.42      0.50        12\n          42       0.82      0.85      0.84        27\n          43       0.45      1.00      0.62         9\n          44       1.00      1.00      1.00         3\n          45       0.50      0.79      0.61        19\n          46       0.96      0.95      0.95       656\n          47       1.00      1.00      1.00         5\n          48       1.00      0.86      0.92         7\n          49       1.00      1.00      1.00         5\n          50       0.50      1.00      0.67         1\n          51       0.55      0.86      0.67         7\n          52       0.43      0.60      0.50         5\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.93      0.98      0.95        64\n          63       1.00      0.67      0.80         3\n          64       1.00      0.00      0.00         1\n          66       0.40      1.00      0.57        14\n          71       0.67      1.00      0.80         2\n          72       0.24      1.00      0.38         4\n          73       0.94      0.96      0.95       567\n          75       0.93      1.00      0.96        13\n          76       0.55      1.00      0.71         6\n          77       0.56      0.91      0.69        11\n          78       0.66      0.98      0.79        53\n          79       0.50      1.00      0.67         6\n          81       0.50      0.50      0.50         2\n          83       0.33      0.50      0.40         2\n          84       0.86      1.00      0.92         6\n          86       0.41      1.00      0.58         7\n          87       0.96      1.00      0.98        27\n          88       0.50      1.00      0.67         7\n          89       0.18      1.00      0.31         2\n          90       0.65      0.92      0.76        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.73      0.92      0.81        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.22      0.67      0.33         6\n         103       0.60      0.60      0.60        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         109       0.00      1.00      0.00         0\n         111       0.86      0.98      0.92        58\n         114       0.00      1.00      0.00         0\n         115       0.50      1.00      0.67         5\n         116       0.96      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.44      1.00      0.62         8\n         119       0.99      0.92      0.95      5640\n\n    accuracy                           0.94     10056\n   macro avg       0.64      0.88      0.67     10056\nweighted avg       0.96      0.94      0.95     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_128_01,"{'name': 'sequential_24', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_11'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_11', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_9', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_9', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_9', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_12', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_11', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_11', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9833466410636902,0.28122660517692566,0.9788666367530823,0.25485607981681824,2699.0,513.0,249.0,660.0,3955.0,0.6794171287733373,['              precision    recall  f1-score   support\n\n           0       0.99      0.98      0.99      1702\n           1       0.40      1.00      0.57         2\n           2       0.95      1.00      0.98        20\n           3       0.98      0.99      0.99       101\n           4       0.57      1.00      0.73         8\n           5       0.42      1.00      0.59         5\n           6       1.00      1.00      1.00         1\n           7       0.67      1.00      0.80        10\n           8       0.60      1.00      0.75         3\n           9       1.00      1.00      1.00         3\n          11       0.60      1.00      0.75         3\n          13       0.88      1.00      0.93         7\n          14       0.38      0.60      0.46         5\n          15       0.77      0.91      0.83        11\n          16       0.79      1.00      0.88        11\n          17       0.37      0.87      0.52        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.98      0.98      0.98       102\n          26       0.88      0.90      0.89        39\n          27       0.86      0.95      0.90        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.78      0.78      0.78         9\n          32       0.86      0.88      0.87        68\n          33       0.00      0.00      0.00         1\n          34       0.93      0.82      0.88        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.36      1.00      0.53        12\n          39       0.86      0.86      0.86         7\n          40       0.92      0.98      0.95        49\n          41       0.83      0.42      0.56        12\n          42       0.82      0.85      0.84        27\n          43       0.38      1.00      0.55         9\n          44       1.00      1.00      1.00         3\n          45       0.52      0.84      0.64        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       0.83      1.00      0.91         5\n          50       0.00      0.00      0.00         1\n          51       0.75      0.86      0.80         7\n          52       0.25      0.40      0.31         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.93      0.98      0.95        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.48      1.00      0.65        14\n          71       1.00      1.00      1.00         2\n          72       0.31      1.00      0.47         4\n          73       0.94      0.96      0.95       567\n          75       0.93      1.00      0.96        13\n          76       0.43      1.00      0.60         6\n          77       0.69      1.00      0.81        11\n          78       0.61      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.50      1.00      0.67         2\n          83       0.25      0.50      0.33         2\n          84       0.86      1.00      0.92         6\n          85       0.00      1.00      0.00         0\n          86       0.58      1.00      0.74         7\n          87       1.00      1.00      1.00        27\n          88       0.78      1.00      0.88         7\n          89       0.50      1.00      0.67         2\n          90       0.65      0.92      0.76        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.88      0.92      0.90        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.40      0.67      0.50         6\n         103       0.74      0.70      0.72        20\n         104       0.95      0.98      0.96       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.88      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.98      0.98       132\n         117       0.67      1.00      0.80         2\n         118       0.50      1.00      0.67         8\n         119       0.99      0.94      0.96      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.66      0.89      0.69     10056\nweighted avg       0.96      0.95      0.95     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_128_02,"{'name': 'sequential_26', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_12'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_12', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_10', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_10', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_10', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_13', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_12', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_12', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9844765067100525,0.2833549380302429,0.9805874824523926,0.2580910623073578,2686.0,465.0,262.0,604.0,3842.0,0.6878519681413885,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.33      1.00      0.50         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.67      1.00      0.80         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.77      1.00      0.87        10\n           8       0.50      1.00      0.67         3\n           9       1.00      1.00      1.00         3\n          11       0.38      1.00      0.55         3\n          13       0.64      1.00      0.78         7\n          14       0.57      0.80      0.67         5\n          15       0.83      0.91      0.87        11\n          16       0.73      1.00      0.85        11\n          17       0.51      0.91      0.66        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       0.98      1.00      0.99        61\n          22       0.00      1.00      0.00         0\n          24       0.80      1.00      0.89        12\n          25       0.99      0.98      0.99       102\n          26       0.92      0.92      0.92        39\n          27       0.84      0.95      0.89        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.75      1.00      0.86         9\n          32       0.88      0.85      0.87        68\n          33       1.00      1.00      1.00         1\n          34       0.97      0.85      0.91        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.41      1.00      0.59        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       0.83      0.42      0.56        12\n          42       0.82      0.85      0.84        27\n          43       0.69      1.00      0.82         9\n          44       1.00      1.00      1.00         3\n          45       0.59      0.84      0.70        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       0.71      1.00      0.83         5\n          50       0.00      0.00      0.00         1\n          51       0.67      0.86      0.75         7\n          52       0.38      0.60      0.46         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.93      0.98      0.95        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.78      1.00      0.88        14\n          71       1.00      1.00      1.00         2\n          72       0.27      1.00      0.42         4\n          73       0.95      0.95      0.95       567\n          75       1.00      1.00      1.00        13\n          76       0.35      1.00      0.52         6\n          77       0.52      1.00      0.69        11\n          78       0.58      0.98      0.73        53\n          79       0.67      1.00      0.80         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.37      1.00      0.54         7\n          87       1.00      1.00      1.00        27\n          88       0.70      1.00      0.82         7\n          89       0.50      1.00      0.67         2\n          90       0.79      0.92      0.85        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.76      0.92      0.83        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.11      0.50      0.18         2\n         102       0.29      0.67      0.40         6\n         103       0.72      0.65      0.68        20\n         104       0.96      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.86      0.98      0.92        58\n         115       0.56      1.00      0.71         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.42      1.00      0.59         8\n         119       0.99      0.94      0.97      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.68      0.90      0.71     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_256_01,"{'name': 'sequential_28', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_13'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_13', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_11', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_11', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_11', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_14', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_13', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_13', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9875730872154236,0.29041364789009094,0.9826959371566772,0.2622378468513489,2696.0,409.0,252.0,552.0,3351.0,0.7035723757557819,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.50      1.00      0.67         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.62      1.00      0.76         8\n           5       0.50      1.00      0.67         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.60      1.00      0.75         3\n           9       1.00      1.00      1.00         3\n          11       0.50      1.00      0.67         3\n          13       0.78      1.00      0.88         7\n          14       0.44      0.80      0.57         5\n          15       0.85      1.00      0.92        11\n          16       0.79      1.00      0.88        11\n          17       0.51      0.85      0.63        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.80      1.00      0.89        12\n          25       0.99      0.98      0.99       102\n          26       0.97      0.90      0.93        39\n          27       0.88      0.95      0.91        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.25      1.00      0.40         1\n          31       0.80      0.89      0.84         9\n          32       0.88      0.88      0.88        68\n          33       1.00      1.00      1.00         1\n          34       0.94      0.85      0.89        34\n          35       0.94      0.94      0.94        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.35      1.00      0.52        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       1.00      0.42      0.59        12\n          42       0.82      0.85      0.84        27\n          43       0.50      1.00      0.67         9\n          44       1.00      1.00      1.00         3\n          45       0.59      0.84      0.70        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       1.00      1.00      1.00         1\n          51       0.86      0.86      0.86         7\n          52       0.33      0.40      0.36         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.88      1.00      0.93        14\n          68       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.33      1.00      0.50         4\n          73       0.95      0.97      0.96       567\n          75       0.93      1.00      0.96        13\n          76       0.86      1.00      0.92         6\n          77       0.65      1.00      0.79        11\n          78       0.67      0.98      0.79        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.50      1.00      0.67         7\n          87       1.00      1.00      1.00        27\n          88       0.64      1.00      0.78         7\n          89       0.50      1.00      0.67         2\n          90       0.69      0.92      0.79        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          95       0.82      0.96      0.88        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.10      0.50      0.17         2\n         102       0.33      0.67      0.44         6\n         103       0.74      0.70      0.72        20\n         104       0.94      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.98      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.50      1.00      0.67         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.72      0.92      0.74     10056\nweighted avg       0.97      0.96      0.96     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_64_01,"{'name': 'sequential_30', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_14'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_14', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_12', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_15', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_14', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_14', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 128)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 128)}}], 'build_input_shape': (None, 46)}",0.9870670437812805,0.2914082109928131,0.9804905652999878,0.2591894268989563,2665.0,476.0,283.0,630.0,3689.0,0.6357280783707533,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.53      1.00      0.70         8\n           5       0.36      1.00      0.53         5\n           6       1.00      1.00      1.00         1\n           7       0.62      1.00      0.77        10\n           8       0.75      1.00      0.86         3\n           9       0.75      1.00      0.86         3\n          11       0.50      0.67      0.57         3\n          13       1.00      1.00      1.00         7\n          14       0.22      0.40      0.29         5\n          15       0.65      1.00      0.79        11\n          16       0.58      1.00      0.73        11\n          17       0.51      0.83      0.63        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.92      1.00      0.96        12\n          25       0.99      0.98      0.99       102\n          26       0.97      0.87      0.92        39\n          27       0.92      0.92      0.92        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.69      1.00      0.82         9\n          32       0.95      0.85      0.90        68\n          33       0.25      1.00      0.40         1\n          34       1.00      0.79      0.89        34\n          35       0.96      0.87      0.92        31\n          36       0.83      1.00      0.91         5\n          37       0.50      0.50      0.50         2\n          38       0.44      1.00      0.62        12\n          39       0.86      0.86      0.86         7\n          40       0.91      0.98      0.94        49\n          41       1.00      0.42      0.59        12\n          42       0.85      0.85      0.85        27\n          43       0.38      1.00      0.55         9\n          44       1.00      1.00      1.00         3\n          45       0.59      0.84      0.70        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.33      1.00      0.50         1\n          51       0.75      0.86      0.80         7\n          52       0.20      0.40      0.27         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.93      0.98      0.95        64\n          63       1.00      1.00      1.00         3\n          64       0.00      0.00      0.00         1\n          66       0.58      1.00      0.74        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.50      1.00      0.67         4\n          73       0.96      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.60      1.00      0.75         6\n          77       0.85      1.00      0.92        11\n          78       0.61      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.33      0.50      0.40         2\n          84       1.00      1.00      1.00         6\n          85       0.00      1.00      0.00         0\n          86       0.50      1.00      0.67         7\n          87       1.00      1.00      1.00        27\n          88       0.50      1.00      0.67         7\n          89       0.10      1.00      0.17         2\n          90       0.79      0.92      0.85        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.81      0.92      0.86        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.00      0.00      0.00         2\n         102       0.19      0.83      0.30         6\n         103       0.76      0.80      0.78        20\n         104       0.96      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         115       0.71      1.00      0.83         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.93      0.96      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.64      0.90      0.68     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_01,"{'name': 'sequential_32', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_15'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_15', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_13', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_16', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_15', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_15', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9916735291481018,0.2956930696964264,0.9856769442558289,0.26731234788894653,2697.0,323.0,251.0,456.0,2743.0,0.6959131893576485,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.67      0.67      0.67         3\n           9       1.00      0.67      0.80         3\n          11       0.43      1.00      0.60         3\n          13       1.00      1.00      1.00         7\n          14       0.44      0.80      0.57         5\n          15       1.00      1.00      1.00        11\n          16       0.73      1.00      0.85        11\n          17       0.83      0.83      0.83        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.95      0.92      0.94        39\n          27       0.88      0.95      0.91        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.00      0.00      0.00         1\n          31       0.75      1.00      0.86         9\n          32       0.95      0.88      0.92        68\n          33       0.50      1.00      0.67         1\n          34       0.97      0.82      0.89        34\n          35       1.00      0.94      0.97        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.52      1.00      0.69        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       1.00      0.42      0.59        12\n          42       0.83      0.93      0.88        27\n          43       0.64      1.00      0.78         9\n          44       1.00      1.00      1.00         3\n          45       0.89      0.84      0.86        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.50      1.00      0.67         1\n          51       0.86      0.86      0.86         7\n          52       0.29      0.40      0.33         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       1.00      1.00      1.00        14\n          71       1.00      1.00      1.00         2\n          72       0.50      1.00      0.67         4\n          73       0.96      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.75      1.00      0.86         6\n          77       0.69      1.00      0.81        11\n          78       0.69      0.98      0.81        53\n          79       0.67      1.00      0.80         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          85       0.00      1.00      0.00         0\n          86       0.47      1.00      0.64         7\n          87       1.00      1.00      1.00        27\n          88       0.70      1.00      0.82         7\n          89       0.29      1.00      0.44         2\n          90       0.79      0.92      0.85        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.81      0.92      0.86        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.20      0.50      0.29         2\n         102       0.50      0.83      0.62         6\n         103       0.65      0.65      0.65        20\n         104       0.96      0.96      0.96       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.44      1.00      0.62         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.71      0.90      0.72     10056\nweighted avg       0.97      0.96      0.97     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_02,"{'name': 'sequential_34', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_16'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_16', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_14', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_17', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_16', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_16', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9884530305862427,0.2948881685733795,0.9837865829467773,0.2676185667514801,2689.0,351.0,259.0,510.0,2970.0,0.6929344197582233,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       1.00      1.00      1.00         8\n           5       0.38      1.00      0.56         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.67      0.67      0.67         3\n           9       0.67      0.67      0.67         3\n          11       0.60      1.00      0.75         3\n          13       1.00      1.00      1.00         7\n          14       0.36      0.80      0.50         5\n          15       1.00      0.91      0.95        11\n          16       0.69      1.00      0.81        11\n          17       0.66      0.83      0.73        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.92      0.92      0.92        39\n          27       0.88      0.95      0.91        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.73      0.89      0.80         9\n          32       0.92      0.84      0.88        68\n          33       1.00      1.00      1.00         1\n          34       0.97      0.82      0.89        34\n          35       1.00      0.94      0.97        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.52      1.00      0.69        12\n          39       0.86      0.86      0.86         7\n          40       0.96      0.98      0.97        49\n          41       1.00      0.42      0.59        12\n          42       0.89      0.93      0.91        27\n          43       0.60      1.00      0.75         9\n          44       1.00      1.00      1.00         3\n          45       0.85      0.89      0.87        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.33      1.00      0.50         1\n          51       0.86      0.86      0.86         7\n          52       0.25      0.20      0.22         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          60       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.93      1.00      0.97        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.36      1.00      0.53         4\n          73       0.95      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.67      1.00      0.80         6\n          77       0.73      1.00      0.85        11\n          78       0.59      0.98      0.74        53\n          79       1.00      1.00      1.00         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          85       0.00      1.00      0.00         0\n          86       0.54      1.00      0.70         7\n          87       1.00      1.00      1.00        27\n          88       0.54      1.00      0.70         7\n          89       0.67      1.00      0.80         2\n          90       0.92      0.92      0.92        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.82      0.96      0.88        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.15      1.00      0.27         2\n         102       0.36      0.67      0.47         6\n         103       0.76      0.80      0.78        20\n         104       0.96      0.98      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.89      0.98      0.93        58\n         115       0.56      1.00      0.71         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.57      1.00      0.73         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.71      0.91      0.72     10056\nweighted avg       0.97      0.96      0.96     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalLSTM_256_01,"{'name': 'sequential_36', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_17'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_17', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_15', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'forward_lstm_12', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'LSTM', 'config': {'name': 'backward_lstm_12', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_18', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_17', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_17', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.986160933971405,0.28235548734664917,0.9815569519996643,0.259829044342041,2688.0,457.0,260.0,603.0,3742.0,0.6940930229658067,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.50      1.00      0.67         2\n           2       0.90      0.95      0.93        20\n           3       0.96      0.99      0.98       101\n           4       0.73      1.00      0.84         8\n           5       0.45      1.00      0.62         5\n           6       1.00      0.00      0.00         1\n           7       0.77      1.00      0.87        10\n           8       0.75      1.00      0.86         3\n           9       0.75      1.00      0.86         3\n          11       0.60      1.00      0.75         3\n          13       0.88      1.00      0.93         7\n          14       0.40      0.80      0.53         5\n          15       0.92      1.00      0.96        11\n          16       0.85      1.00      0.92        11\n          17       0.45      0.85      0.59        46\n          18       0.97      1.00      0.99        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.92      0.90      0.91        39\n          27       0.84      0.95      0.89        39\n          28       0.92      0.92      0.92        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.73      0.89      0.80         9\n          32       0.87      0.88      0.88        68\n          33       1.00      1.00      1.00         1\n          34       0.97      0.82      0.89        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.33      0.50      0.40         2\n          38       0.41      1.00      0.59        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       0.71      0.42      0.53        12\n          42       0.79      0.85      0.82        27\n          43       0.56      1.00      0.72         9\n          44       1.00      1.00      1.00         3\n          45       0.53      0.84      0.65        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       0.88      1.00      0.93         7\n          49       1.00      1.00      1.00         5\n          50       0.25      1.00      0.40         1\n          51       0.86      0.86      0.86         7\n          52       0.33      0.40      0.36         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.54      1.00      0.70        14\n          71       1.00      1.00      1.00         2\n          72       0.33      1.00      0.50         4\n          73       0.95      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.67      1.00      0.80         6\n          77       0.50      0.91      0.65        11\n          78       0.64      0.98      0.78        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.39      1.00      0.56         7\n          87       1.00      1.00      1.00        27\n          88       0.88      1.00      0.93         7\n          89       0.50      1.00      0.67         2\n          90       0.73      0.92      0.81        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.82      0.96      0.88        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         101       0.12      0.50      0.20         2\n         102       0.40      0.67      0.50         6\n         103       0.75      0.75      0.75        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.89      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.99      0.98       132\n         117       0.67      1.00      0.80         2\n         118       0.38      1.00      0.55         8\n         119       0.99      0.94      0.97      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.70      0.90      0.73     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,2048,10,32,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_01,"{'name': 'sequential_1', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9883148670196533,0.38352352380752563,0.9818719625473022,0.32919788360595703,2671.0,455.0,277.0,600.0,3746.0,0.6682388119273459,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.91      1.00      0.95        20\n           3       0.99      0.98      0.99       101\n           4       0.67      1.00      0.80         8\n           5       0.50      0.80      0.62         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.50      0.67      0.57         3\n           9       0.50      0.67      0.57         3\n          10       0.00      1.00      0.00         0\n          11       0.67      0.67      0.67         3\n          13       0.78      1.00      0.88         7\n          14       0.31      0.80      0.44         5\n          15       0.92      1.00      0.96        11\n          16       0.61      1.00      0.76        11\n          17       0.52      0.87      0.65        46\n          18       0.97      1.00      0.99        33\n          19       0.86      1.00      0.92         6\n          20       0.98      1.00      0.99        61\n          24       0.80      1.00      0.89        12\n          25       0.99      0.98      0.99       102\n          26       0.89      0.85      0.87        39\n          27       0.93      0.95      0.94        39\n          28       0.92      0.92      0.92        12\n          29       1.00      1.00      1.00         1\n          30       0.33      1.00      0.50         1\n          31       0.69      1.00      0.82         9\n          32       0.94      0.85      0.89        68\n          33       0.50      1.00      0.67         1\n          34       0.96      0.76      0.85        34\n          35       1.00      0.94      0.97        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.40      1.00      0.57        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       0.83      0.42      0.56        12\n          42       0.78      0.93      0.85        27\n          43       0.31      1.00      0.47         9\n          44       1.00      1.00      1.00         3\n          45       0.74      0.89      0.81        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.20      1.00      0.33         1\n          51       0.86      0.86      0.86         7\n          52       0.29      0.40      0.33         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.68      0.93      0.79        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.67      1.00      0.80         4\n          73       0.95      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.55      1.00      0.71         6\n          77       0.85      1.00      0.92        11\n          78       0.62      0.98      0.76        53\n          79       0.71      0.83      0.77         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.58      1.00      0.74         7\n          87       1.00      1.00      1.00        27\n          88       0.37      1.00      0.54         7\n          89       0.67      1.00      0.80         2\n          90       0.73      0.92      0.81        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.79      0.92      0.85        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.14      0.50      0.22         2\n         102       0.25      0.83      0.38         6\n         103       0.67      0.70      0.68        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.88      0.98      0.93        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.97      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.42      1.00      0.59         8\n         119       0.99      0.94      0.97      5640\n\n    accuracy                           0.95     10056\n   macro avg       0.67      0.90      0.70     10056\nweighted avg       0.97      0.95      0.96     10056\n'],1000,1024,20,64,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_256_01,"{'name': 'sequential_3', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_1'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_1', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_1', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_1', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_1', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 512)}}], 'build_input_shape': (None, 46)}",0.990196704864502,0.3892664313316345,0.9841015934944153,0.33575180172920227,2690.0,375.0,258.0,508.0,2978.0,0.6954929909383168,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       1.00      1.00      1.00         2\n           2       0.91      1.00      0.95        20\n           3       0.99      0.98      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.42      1.00      0.59         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       1.00      0.67      0.80         3\n           9       0.67      0.67      0.67         3\n          11       0.75      1.00      0.86         3\n          13       0.75      0.86      0.80         7\n          14       0.30      0.60      0.40         5\n          15       1.00      0.91      0.95        11\n          16       0.73      1.00      0.85        11\n          17       0.62      0.87      0.73        46\n          18       1.00      1.00      1.00        33\n          19       0.75      1.00      0.86         6\n          20       1.00      1.00      1.00        61\n          24       0.92      1.00      0.96        12\n          25       0.99      0.98      0.99       102\n          26       0.92      0.92      0.92        39\n          27       0.90      0.95      0.93        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.82      1.00      0.90         9\n          32       0.94      0.90      0.92        68\n          33       0.20      1.00      0.33         1\n          34       0.93      0.79      0.86        34\n          35       0.91      0.94      0.92        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.63      1.00      0.77        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       1.00      0.42      0.59        12\n          42       0.86      0.93      0.89        27\n          43       0.53      1.00      0.69         9\n          44       1.00      1.00      1.00         3\n          45       0.79      0.79      0.79        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       0.88      1.00      0.93         7\n          49       1.00      1.00      1.00         5\n          50       0.17      1.00      0.29         1\n          51       0.86      0.86      0.86         7\n          52       0.29      0.40      0.33         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.94      0.98      0.96        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.81      0.93      0.87        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.36      1.00      0.53         4\n          73       0.95      0.97      0.96       567\n          74       0.00      1.00      0.00         0\n          75       1.00      1.00      1.00        13\n          76       0.46      1.00      0.63         6\n          77       0.85      1.00      0.92        11\n          78       0.65      0.98      0.78        53\n          79       0.67      1.00      0.80         6\n          81       0.67      1.00      0.80         2\n          82       0.00      1.00      0.00         0\n          83       0.50      0.50      0.50         2\n          84       0.75      1.00      0.86         6\n          86       0.58      1.00      0.74         7\n          87       1.00      1.00      1.00        27\n          88       0.44      1.00      0.61         7\n          89       0.67      1.00      0.80         2\n          90       0.79      0.92      0.85        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.75      0.88      0.81        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.12      0.50      0.20         2\n         102       0.31      0.67      0.42         6\n         103       0.74      0.70      0.72        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.89      0.98      0.93        58\n         115       0.56      1.00      0.71         5\n         116       0.98      0.99      0.99       132\n         117       1.00      1.00      1.00         2\n         118       0.57      1.00      0.73         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.69      0.91      0.72     10056\nweighted avg       0.97      0.96      0.96     10056\n'],1000,1024,20,64,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_256,"{'name': 'sequential_5', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_2'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_2', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 1024, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_2', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_2', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 1024)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_2', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 512)}}], 'build_input_shape': (None, 46)}",0.9918490648269653,0.39488574862480164,0.9851194620132446,0.33773934841156006,2689.0,351.0,259.0,481.0,2942.0,0.7047149964379933,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.91      1.00      0.95        20\n           3       0.99      0.98      0.99       101\n           4       0.80      1.00      0.89         8\n           5       0.50      1.00      0.67         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.67      0.67      0.67         3\n           9       1.00      0.67      0.80         3\n          10       0.00      1.00      0.00         0\n          11       0.60      1.00      0.75         3\n          13       0.88      1.00      0.93         7\n          14       0.43      0.60      0.50         5\n          15       1.00      1.00      1.00        11\n          16       0.69      1.00      0.81        11\n          17       0.72      0.85      0.78        46\n          18       1.00      0.97      0.98        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          24       0.73      0.92      0.81        12\n          25       0.99      0.98      0.99       102\n          26       0.92      0.92      0.92        39\n          27       0.90      0.95      0.93        39\n          28       0.92      0.92      0.92        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.75      1.00      0.86         9\n          32       0.97      0.90      0.93        68\n          33       0.20      1.00      0.33         1\n          34       1.00      0.82      0.90        34\n          35       1.00      0.94      0.97        31\n          36       1.00      1.00      1.00         5\n          37       0.33      0.50      0.40         2\n          38       0.86      1.00      0.92        12\n          39       0.86      0.86      0.86         7\n          40       0.92      0.98      0.95        49\n          41       1.00      0.42      0.59        12\n          42       0.78      0.93      0.85        27\n          43       0.53      1.00      0.69         9\n          44       1.00      1.00      1.00         3\n          45       0.84      0.84      0.84        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.00      0.00      0.00         1\n          51       0.86      0.86      0.86         7\n          52       0.29      0.40      0.33         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          62       0.97      0.98      0.98        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       1.00      0.93      0.96        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.67      1.00      0.80         4\n          73       0.95      0.96      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.60      1.00      0.75         6\n          77       0.79      1.00      0.88        11\n          78       0.65      0.98      0.78        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.33      0.50      0.40         2\n          84       1.00      1.00      1.00         6\n          86       0.64      1.00      0.78         7\n          87       1.00      1.00      1.00        27\n          88       0.58      1.00      0.74         7\n          89       1.00      0.50      0.67         2\n          90       0.92      0.92      0.92        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.85      0.92      0.88        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.17      0.50      0.25         2\n         102       0.36      0.83      0.50         6\n         103       0.79      0.75      0.77        20\n         104       0.96      0.98      0.97       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.89      0.98      0.93        58\n         115       0.56      1.00      0.71         5\n         116       0.98      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.42      1.00      0.59         8\n         119       0.99      0.96      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.71      0.89      0.73     10056\nweighted avg       0.97      0.96      0.97     10056\n'],1000,1024,20,64,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_128_01,"{'name': 'sequential_7', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_3'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_3', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_3', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_3', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 128, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_3', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 256)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 256)}}], 'build_input_shape': (None, 46)}",0.9905112981796265,0.39107125997543335,0.9841986298561096,0.33568820357322693,2693.0,341.0,255.0,493.0,2882.0,0.6991765169560308,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.91      1.00      0.95        20\n           3       0.99      0.98      0.99       101\n           4       0.80      1.00      0.89         8\n           5       0.45      1.00      0.62         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       1.00      0.67      0.80         3\n           9       1.00      0.67      0.80         3\n          11       0.60      1.00      0.75         3\n          13       0.70      1.00      0.82         7\n          14       0.40      0.80      0.53         5\n          15       1.00      1.00      1.00        11\n          16       0.73      1.00      0.85        11\n          17       0.71      0.89      0.79        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       0.97      1.00      0.98        61\n          24       0.92      1.00      0.96        12\n          25       0.99      0.98      0.99       102\n          26       0.93      0.95      0.94        39\n          27       0.86      0.97      0.92        39\n          28       0.79      0.92      0.85        12\n          29       1.00      1.00      1.00         1\n          30       0.50      1.00      0.67         1\n          31       0.69      1.00      0.82         9\n          32       0.89      0.84      0.86        68\n          33       1.00      1.00      1.00         1\n          34       1.00      0.85      0.92        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.33      0.50      0.40         2\n          38       0.67      1.00      0.80        12\n          39       0.86      0.86      0.86         7\n          40       0.98      0.98      0.98        49\n          41       0.83      0.42      0.56        12\n          42       0.82      0.85      0.84        27\n          43       0.53      1.00      0.69         9\n          44       0.75      1.00      0.86         3\n          45       0.84      0.84      0.84        19\n          46       0.96      0.96      0.96       656\n          47       1.00      1.00      1.00         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.33      1.00      0.50         1\n          51       0.86      0.86      0.86         7\n          52       0.33      0.40      0.36         5\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       1.00      1.00      1.00         3\n          64       1.00      0.00      0.00         1\n          66       0.93      0.93      0.93        14\n          70       0.00      1.00      0.00         0\n          71       1.00      1.00      1.00         2\n          72       0.57      1.00      0.73         4\n          73       0.96      0.97      0.97       567\n          75       1.00      1.00      1.00        13\n          76       0.75      1.00      0.86         6\n          77       0.79      1.00      0.88        11\n          78       0.60      0.98      0.75        53\n          79       0.75      1.00      0.86         6\n          81       0.67      1.00      0.80         2\n          83       0.33      0.50      0.40         2\n          84       0.86      1.00      0.92         6\n          85       0.00      1.00      0.00         0\n          86       0.41      1.00      0.58         7\n          87       1.00      1.00      1.00        27\n          88       0.37      1.00      0.54         7\n          89       0.50      1.00      0.67         2\n          90       0.73      0.92      0.81        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          95       0.79      0.96      0.87        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.10      0.50      0.17         2\n         102       0.45      0.83      0.59         6\n         103       0.74      0.70      0.72        20\n         104       0.96      0.97      0.96       110\n         105       1.00      1.00      1.00         2\n         106       0.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.89      0.98      0.93        58\n         115       0.56      1.00      0.71         5\n         116       0.98      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.50      1.00      0.67         8\n         119       0.99      0.95      0.97      5640\n\n    accuracy                           0.96     10056\n   macro avg       0.71      0.91      0.74     10056\nweighted avg       0.97      0.96      0.96     10056\n'],1000,2048,20,64,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_256_01,"{'name': 'sequential_9', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_4'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_4', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_4', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_4', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.1, 'seed': None, 'noise_shape': None}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_4', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 512)}}], 'build_input_shape': (None, 46)}",0.9934057593345642,0.39159998297691345,0.9863554835319519,0.3413044810295105,2702.0,308.0,246.0,431.0,2528.0,0.7174025943450041,['              precision    recall  f1-score   support\n\n           0       0.99      0.99      0.99      1702\n           1       0.67      1.00      0.80         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.42      1.00      0.59         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       1.00      0.67      0.80         3\n           9       0.67      0.67      0.67         3\n          11       0.60      1.00      0.75         3\n          13       1.00      1.00      1.00         7\n          14       0.43      0.60      0.50         5\n          15       1.00      1.00      1.00        11\n          16       0.85      1.00      0.92        11\n          17       0.60      0.83      0.70        46\n          18       0.97      0.97      0.97        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.86      1.00      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.95      0.90      0.92        39\n          27       0.88      0.95      0.91        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.33      1.00      0.50         1\n          31       0.82      1.00      0.90         9\n          32       0.94      0.88      0.91        68\n          33       0.33      1.00      0.50         1\n          34       1.00      0.82      0.90        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.48      1.00      0.65        12\n          39       0.86      0.86      0.86         7\n          40       0.94      0.98      0.96        49\n          41       1.00      0.42      0.59        12\n          42       0.83      0.93      0.88        27\n          43       0.47      1.00      0.64         9\n          44       1.00      1.00      1.00         3\n          45       0.83      0.79      0.81        19\n          46       0.96      0.96      0.96       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       1.00      1.00      1.00         1\n          51       0.86      0.86      0.86         7\n          52       0.43      0.60      0.50         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.75      1.00      0.86         6\n          57       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.93      0.93      0.93        14\n          71       1.00      1.00      1.00         2\n          72       0.67      1.00      0.80         4\n          73       0.96      0.96      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.75      1.00      0.86         6\n          77       0.92      1.00      0.96        11\n          78       0.80      0.98      0.88        53\n          79       0.67      1.00      0.80         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       1.00      1.00      1.00         6\n          86       0.47      1.00      0.64         7\n          87       1.00      1.00      1.00        27\n          88       0.70      1.00      0.82         7\n          89       0.67      1.00      0.80         2\n          90       0.92      0.92      0.92        12\n          92       0.00      1.00      0.00         0\n          93       1.00      1.00      1.00         2\n          94       0.00      1.00      0.00         0\n          95       0.79      0.92      0.85        24\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.14      0.50      0.22         2\n         102       0.50      0.67      0.57         6\n         103       0.72      0.65      0.68        20\n         104       0.96      0.97      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       1.00      1.00      1.00         2\n         111       0.90      0.98      0.94        58\n         113       0.00      1.00      0.00         0\n         115       0.56      1.00      0.71         5\n         116       0.98      0.99      0.98       132\n         117       1.00      1.00      1.00         2\n         118       0.47      1.00      0.64         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.97     10056\n   macro avg       0.74      0.91      0.75     10056\nweighted avg       0.97      0.97      0.97     10056\n'],1000,2048,20,64,False,False,False,,post,accuracy,macro,True,False,5
architecture_name,summary,best_model_training_acc,best_model_training_f1,best_model_validation_acc,best_model_validation_f1,average_tp,average_fp,average_fn,average_errors,average_tokens,sci_f1,reports,vocab_size,embedding_dim,epochs,batch_size,lemmatize,stem,remove_stopwords,custom_stopwords,padding,selection_metric,f1_type,use_sample_weights,early_stopping,early_stopping_patience
BidirectionalGRU_256,"{'name': 'sequential_11', 'trainable': True, 'dtype': 'float32', 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': (None, 46), 'dtype': 'float32', 'sparse': False, 'name': 'input_layer_5'}, 'registered_name': None}, {'module': 'keras.layers', 'class_name': 'Embedding', 'config': {'name': 'embedding_5', 'trainable': True, 'dtype': 'float32', 'input_dim': 1001, 'output_dim': 2048, 'embeddings_initializer': {'module': 'keras.initializers', 'class_name': 'RandomUniform', 'config': {'minval': -0.05, 'maxval': 0.05, 'seed': None}, 'registered_name': None}, 'embeddings_regularizer': None, 'activity_regularizer': None, 'embeddings_constraint': None, 'mask_zero': False}, 'registered_name': None, 'build_config': {'input_shape': (None, 46)}}, {'module': 'keras.layers', 'class_name': 'Bidirectional', 'config': {'name': 'bidirectional_5', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'forward_gru_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, 'merge_mode': 'concat', 'backward_layer': {'module': 'keras.layers', 'class_name': 'GRU', 'config': {'name': 'backward_gru_5', 'trainable': True, 'dtype': 'float32', 'return_sequences': True, 'return_state': False, 'go_backwards': True, 'stateful': False, 'unroll': False, 'zero_output_for_mask': True, 'units': 256, 'activation': 'tanh', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'recurrent_initializer': {'module': 'keras.initializers', 'class_name': 'OrthogonalInitializer', 'config': {'gain': 1.0, 'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'reset_after': True, 'seed': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 2048)}}, {'module': 'keras.layers', 'class_name': 'TimeDistributed', 'config': {'name': 'time_distributed_5', 'trainable': True, 'dtype': 'float32', 'layer': {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 120, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': (None, 512)}}}, 'registered_name': None, 'build_config': {'input_shape': (None, 46, 512)}}], 'build_input_shape': (None, 46)}",0.9939652681350708,0.4009353220462799,0.9870340824127197,0.343930184841156,2708.0,301.0,240.0,426.0,2424.0,0.7132399308417086,['              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99      1702\n           1       1.00      1.00      1.00         2\n           2       0.95      1.00      0.98        20\n           3       0.99      0.99      0.99       101\n           4       0.89      1.00      0.94         8\n           5       0.56      1.00      0.71         5\n           6       1.00      1.00      1.00         1\n           7       0.83      1.00      0.91        10\n           8       0.60      1.00      0.75         3\n           9       1.00      1.00      1.00         3\n          11       0.60      1.00      0.75         3\n          13       0.88      1.00      0.93         7\n          14       0.60      0.60      0.60         5\n          15       1.00      0.91      0.95        11\n          16       0.85      1.00      0.92        11\n          17       0.78      0.87      0.82        46\n          18       1.00      1.00      1.00        33\n          19       0.86      1.00      0.92         6\n          20       1.00      1.00      1.00        61\n          22       0.00      1.00      0.00         0\n          24       0.92      0.92      0.92        12\n          25       0.99      0.98      0.99       102\n          26       0.97      0.92      0.95        39\n          27       0.88      0.95      0.91        39\n          28       0.85      0.92      0.88        12\n          29       1.00      1.00      1.00         1\n          30       0.33      1.00      0.50         1\n          31       0.80      0.89      0.84         9\n          32       0.95      0.91      0.93        68\n          33       0.50      1.00      0.67         1\n          34       1.00      0.82      0.90        34\n          35       0.97      0.94      0.95        31\n          36       1.00      1.00      1.00         5\n          37       0.50      0.50      0.50         2\n          38       0.71      1.00      0.83        12\n          39       0.86      0.86      0.86         7\n          40       0.89      0.98      0.93        49\n          41       1.00      0.42      0.59        12\n          42       0.81      0.93      0.86        27\n          43       0.53      1.00      0.69         9\n          44       1.00      1.00      1.00         3\n          45       0.89      0.89      0.89        19\n          46       0.97      0.96      0.97       656\n          47       1.00      0.80      0.89         5\n          48       1.00      1.00      1.00         7\n          49       1.00      1.00      1.00         5\n          50       0.33      1.00      0.50         1\n          51       0.86      0.86      0.86         7\n          52       0.20      0.20      0.20         5\n          53       0.00      1.00      0.00         0\n          54       0.83      0.83      0.83         6\n          55       0.00      1.00      0.00         0\n          56       0.50      1.00      0.67         6\n          57       0.00      1.00      0.00         0\n          59       0.00      1.00      0.00         0\n          62       0.95      0.98      0.97        64\n          63       0.75      1.00      0.86         3\n          64       1.00      0.00      0.00         1\n          66       0.93      0.93      0.93        14\n          71       1.00      1.00      1.00         2\n          72       0.44      1.00      0.62         4\n          73       0.96      0.97      0.96       567\n          75       1.00      1.00      1.00        13\n          76       0.67      1.00      0.80         6\n          77       0.79      1.00      0.88        11\n          78       0.79      0.98      0.87        53\n          79       1.00      1.00      1.00         6\n          81       0.67      1.00      0.80         2\n          83       0.50      0.50      0.50         2\n          84       0.86      1.00      0.92         6\n          86       0.64      1.00      0.78         7\n          87       1.00      1.00      1.00        27\n          88       0.54      1.00      0.70         7\n          89       0.67      1.00      0.80         2\n          90       0.85      0.92      0.88        12\n          92       0.00      1.00      0.00         0\n          93       0.67      1.00      0.80         2\n          94       0.00      1.00      0.00         0\n          95       0.88      0.92      0.90        24\n          96       0.00      1.00      0.00         0\n          97       1.00      1.00      1.00         1\n          98       0.50      0.50      0.50         2\n          99       0.00      1.00      0.00         0\n         100       0.00      1.00      0.00         0\n         101       0.14      0.50      0.22         2\n         102       0.45      0.83      0.59         6\n         103       0.76      0.80      0.78        20\n         104       0.96      0.98      0.97       110\n         105       1.00      1.00      1.00         2\n         106       1.00      0.00      0.00         1\n         108       0.50      1.00      0.67         2\n         111       0.93      0.98      0.96        58\n         115       0.56      1.00      0.71         5\n         116       0.98      0.99      0.99       132\n         117       1.00      1.00      1.00         2\n         118       0.44      1.00      0.62         8\n         119       0.99      0.96      0.98      5640\n\n    accuracy                           0.97     10056\n   macro avg       0.72      0.91      0.74     10056\nweighted avg       0.98      0.97      0.97     10056\n'],1000,2048,20,64,False,False,False,,post,accuracy,macro,True,False,5
